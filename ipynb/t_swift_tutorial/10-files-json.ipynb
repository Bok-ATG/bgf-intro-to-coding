{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taylor Swift Python Tutorial: Files & JSON\n",
    "\n",
    "Learn to read and write data files! Working with files is essential for data persistence, configuration, and sharing Taylor Swift data between programs.\n",
    "\n",
    "## Learning Goals\n",
    "- Master **file reading and writing** operations\n",
    "- Handle different **file formats** (text, CSV, JSON)\n",
    "- Use **context managers** (`with` statements) safely\n",
    "- Process **JSON data** from APIs and files\n",
    "- Build data **persistence systems** for music data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic File Operations\n",
    "\n",
    "Start with simple text file operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample Taylor Swift data\n",
    "song_list = [\n",
    "    \"Love Story - A timeless country-pop ballad\",\n",
    "    \"Shake It Off - Upbeat pop anthem about resilience\", \n",
    "    \"All Too Well - Emotional breakup song, fan favorite\",\n",
    "    \"Anti-Hero - Introspective pop track from Midnights\",\n",
    "    \"cardigan - Indie-folk song from folklore era\"\n",
    "]\n",
    "\n",
    "# Writing to a text file\n",
    "print(\"=== Writing Song List to File ===\")\n",
    "\n",
    "# Method 1: Traditional file handling (not recommended)\n",
    "file = open('taylor_songs_basic.txt', 'w')\n",
    "for song in song_list:\n",
    "    file.write(song + '\\n')\n",
    "file.close()\n",
    "\n",
    "print(\"‚úì Created taylor_songs_basic.txt\")\n",
    "\n",
    "# Method 2: Using context manager (recommended)\n",
    "with open('taylor_songs.txt', 'w') as file:\n",
    "    for song in song_list:\n",
    "        file.write(song + '\\n')\n",
    "\n",
    "print(\"‚úì Created taylor_songs.txt with context manager\")\n",
    "\n",
    "# Method 3: Write all at once\n",
    "with open('taylor_songs_all.txt', 'w') as file:\n",
    "    file.write('\\n'.join(song_list))\n",
    "\n",
    "print(\"‚úì Created taylor_songs_all.txt\")\n",
    "\n",
    "# Reading from a text file\n",
    "print(\"\\n=== Reading Song List from File ===\")\n",
    "\n",
    "# Method 1: Read entire file\n",
    "with open('taylor_songs.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    print(f\"File content ({len(content)} characters):\")\n",
    "    print(content[:100] + \"...\" if len(content) > 100 else content)\n",
    "\n",
    "# Method 2: Read line by line\n",
    "with open('taylor_songs.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    print(f\"\\nRead {len(lines)} lines:\")\n",
    "    for i, line in enumerate(lines[:3], 1):\n",
    "        print(f\"  {i}. {line.strip()}\")\n",
    "\n",
    "# Method 3: Iterate through file (memory efficient)\n",
    "print(\"\\nProcessing file line by line:\")\n",
    "song_count = 0\n",
    "with open('taylor_songs.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        if 'pop' in line.lower():\n",
    "            print(f\"  Found pop song: {line.strip()}\")\n",
    "        song_count += 1\n",
    "\n",
    "print(f\"\\nProcessed {song_count} songs total\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with CSV Data\n",
    "\n",
    "Handle structured data in CSV format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "# Sample Taylor Swift album data\n",
    "album_data = [\n",
    "    ['Album', 'Year', 'Genre', 'Tracks', 'Sales_Millions'],\n",
    "    ['Taylor Swift', 2006, 'Country', 11, 2.5],\n",
    "    ['Fearless', 2008, 'Country', 13, 7.2],\n",
    "    ['Speak Now', 2010, 'Country', 14, 4.7],\n",
    "    ['Red', 2012, 'Country-Pop', 16, 6.2],\n",
    "    ['1989', 2014, 'Pop', 13, 6.2],\n",
    "    ['reputation', 2017, 'Pop', 15, 2.3],\n",
    "    ['Lover', 2019, 'Pop', 18, 3.2],\n",
    "    ['folklore', 2020, 'Alternative', 16, 1.3],\n",
    "    ['evermore', 2020, 'Alternative', 15, 0.8],\n",
    "    ['Midnights', 2022, 'Pop', 13, 3.5]\n",
    "]\n",
    "\n",
    "print(\"=== Writing CSV Data ===\")\n",
    "\n",
    "# Write CSV file\n",
    "with open('taylor_albums.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(album_data)\n",
    "\n",
    "print(\"‚úì Created taylor_albums.csv\")\n",
    "\n",
    "# Write with custom delimiter\n",
    "with open('taylor_albums_pipe.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='|')\n",
    "    writer.writerows(album_data)\n",
    "\n",
    "print(\"‚úì Created taylor_albums_pipe.csv with | delimiter\")\n",
    "\n",
    "print(\"\\n=== Reading CSV Data ===\")\n",
    "\n",
    "# Read CSV file\n",
    "albums = []\n",
    "with open('taylor_albums.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    header = next(reader)  # Skip header row\n",
    "    print(f\"Headers: {header}\")\n",
    "    \n",
    "    for row in reader:\n",
    "        albums.append({\n",
    "            'album': row[0],\n",
    "            'year': int(row[1]),\n",
    "            'genre': row[2],\n",
    "            'tracks': int(row[3]),\n",
    "            'sales': float(row[4])\n",
    "        })\n",
    "\n",
    "print(f\"\\nLoaded {len(albums)} albums:\")\n",
    "for album in albums[:3]:\n",
    "    print(f\"  {album['album']} ({album['year']}): {album['genre']}, {album['sales']}M sales\")\n",
    "\n",
    "# Using DictReader for easier access\n",
    "print(\"\\n=== Using CSV DictReader ===\")\n",
    "\n",
    "albums_dict = []\n",
    "with open('taylor_albums.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        albums_dict.append({\n",
    "            'album': row['Album'],\n",
    "            'year': int(row['Year']),\n",
    "            'genre': row['Genre'],\n",
    "            'tracks': int(row['Tracks']),\n",
    "            'sales': float(row['Sales_Millions'])\n",
    "        })\n",
    "\n",
    "# Analyze the data\n",
    "total_sales = sum(album['sales'] for album in albums_dict)\n",
    "pop_albums = [album for album in albums_dict if 'Pop' in album['genre']]\n",
    "best_selling = max(albums_dict, key=lambda x: x['sales'])\n",
    "\n",
    "print(f\"\\nAnalysis Results:\")\n",
    "print(f\"  Total sales: {total_sales:.1f} million\")\n",
    "print(f\"  Pop albums: {len(pop_albums)}\")\n",
    "print(f\"  Best selling: {best_selling['album']} ({best_selling['sales']}M)\")\n",
    "\n",
    "# Write analysis results\n",
    "analysis_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['Total Albums', len(albums_dict)],\n",
    "    ['Total Sales (Millions)', total_sales],\n",
    "    ['Pop Albums Count', len(pop_albums)],\n",
    "    ['Best Selling Album', f\"{best_selling['album']} ({best_selling['sales']}M)\"]\n",
    "]\n",
    "\n",
    "with open('taylor_analysis.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(analysis_data)\n",
    "\n",
    "print(\"\\n‚úì Created taylor_analysis.csv with results\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Data Handling\n",
    "\n",
    "Work with JSON for structured data and API responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Complex Taylor Swift data structure\n",
    "taylor_discography = {\n",
    "    \"artist_info\": {\n",
    "        \"name\": \"Taylor Swift\",\n",
    "        \"birth_date\": \"1989-12-13\",\n",
    "        \"debut_year\": 2006,\n",
    "        \"genres\": [\"Country\", \"Pop\", \"Alternative\", \"Folk\"],\n",
    "        \"instruments\": [\"Vocals\", \"Guitar\", \"Piano\", \"Banjo\"]\n",
    "    },\n",
    "    \"albums\": {\n",
    "        \"folklore\": {\n",
    "            \"release_date\": \"2020-07-24\",\n",
    "            \"genre\": \"Alternative\",\n",
    "            \"label\": \"Republic Records\",\n",
    "            \"produced_by\": [\"Aaron Dessner\", \"Taylor Swift\", \"Jack Antonoff\"],\n",
    "            \"tracks\": [\n",
    "                {\"title\": \"the 1\", \"duration\": 210, \"writers\": [\"Taylor Swift\", \"Aaron Dessner\"]},\n",
    "                {\"title\": \"cardigan\", \"duration\": 219, \"writers\": [\"Taylor Swift\", \"Aaron Dessner\"]},\n",
    "                {\"title\": \"the last great american dynasty\", \"duration\": 231, \"writers\": [\"Taylor Swift\", \"Aaron Dessner\"]}\n",
    "            ],\n",
    "            \"awards\": [\"Grammy Album of the Year 2021\"],\n",
    "            \"sales_millions\": 1.3\n",
    "        },\n",
    "        \"Midnights\": {\n",
    "            \"release_date\": \"2022-10-21\",\n",
    "            \"genre\": \"Pop\",\n",
    "            \"label\": \"Republic Records\",\n",
    "            \"produced_by\": [\"Jack Antonoff\", \"Taylor Swift\"],\n",
    "            \"tracks\": [\n",
    "                {\"title\": \"Lavender Haze\", \"duration\": 202, \"writers\": [\"Taylor Swift\", \"Jack Antonoff\"]},\n",
    "                {\"title\": \"Anti-Hero\", \"duration\": 200, \"writers\": [\"Taylor Swift\", \"Jack Antonoff\"]},\n",
    "                {\"title\": \"Midnight Rain\", \"duration\": 174, \"writers\": [\"Taylor Swift\", \"Jack Antonoff\"]}\n",
    "            ],\n",
    "            \"awards\": [],\n",
    "            \"sales_millions\": 3.5\n",
    "        }\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"last_updated\": datetime.now().isoformat(),\n",
    "        \"source\": \"Fan compilation\",\n",
    "        \"version\": \"1.0\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== Writing JSON Data ===\")\n",
    "\n",
    "# Write JSON file with pretty formatting\n",
    "with open('taylor_discography.json', 'w') as jsonfile:\n",
    "    json.dump(taylor_discography, jsonfile, indent=2)\n",
    "\n",
    "print(\"‚úì Created taylor_discography.json\")\n",
    "\n",
    "# Write compact JSON\n",
    "with open('taylor_discography_compact.json', 'w') as jsonfile:\n",
    "    json.dump(taylor_discography, jsonfile, separators=(',', ':'))\n",
    "\n",
    "print(\"‚úì Created taylor_discography_compact.json\")\n",
    "\n",
    "print(\"\\n=== Reading JSON Data ===\")\n",
    "\n",
    "# Read JSON file\n",
    "with open('taylor_discography.json', 'r') as jsonfile:\n",
    "    loaded_data = json.load(jsonfile)\n",
    "\n",
    "print(f\"Loaded data for: {loaded_data['artist_info']['name']}\")\n",
    "print(f\"Albums in dataset: {len(loaded_data['albums'])}\")\n",
    "print(f\"Last updated: {loaded_data['metadata']['last_updated']}\")\n",
    "\n",
    "# Extract and analyze album information\n",
    "print(\"\\n=== Album Analysis ===\")\n",
    "\n",
    "for album_name, album_data in loaded_data['albums'].items():\n",
    "    track_count = len(album_data['tracks'])\n",
    "    total_duration = sum(track['duration'] for track in album_data['tracks'])\n",
    "    avg_duration = total_duration / track_count if track_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{album_name} ({album_data['genre']})\":)\n",
    "    print(f\"  Released: {album_data['release_date']}\")\n",
    "    print(f\"  Tracks: {track_count}\")\n",
    "    print(f\"  Total duration: {total_duration/60:.1f} minutes\")\n",
    "    print(f\"  Average track length: {avg_duration/60:.2f} minutes\")\n",
    "    print(f\"  Sales: {album_data['sales_millions']}M\")\n",
    "    print(f\"  Producers: {', '.join(album_data['produced_by'])}\")\n",
    "\n",
    "# Find all unique collaborators\n",
    "all_writers = set()\n",
    "all_producers = set()\n",
    "\n",
    "for album_data in loaded_data['albums'].values():\n",
    "    all_producers.update(album_data['produced_by'])\n",
    "    for track in album_data['tracks']:\n",
    "        all_writers.update(track['writers'])\n",
    "\n",
    "collaborators = (all_writers | all_producers) - {\"Taylor Swift\"}\n",
    "\n",
    "print(f\"\\n=== Collaboration Network ===\")\n",
    "print(f\"Unique collaborators: {len(collaborators)}\")\n",
    "print(f\"Writers/Producers: {', '.join(sorted(collaborators))}\")\n",
    "\n",
    "# Create summary data\n",
    "summary = {\n",
    "    \"artist\": loaded_data['artist_info']['name'],\n",
    "    \"total_albums\": len(loaded_data['albums']),\n",
    "    \"total_tracks\": sum(len(album['tracks']) for album in loaded_data['albums'].values()),\n",
    "    \"total_sales\": sum(album['sales_millions'] for album in loaded_data['albums'].values()),\n",
    "    \"genres\": list(set(album['genre'] for album in loaded_data['albums'].values())),\n",
    "    \"collaborators\": sorted(list(collaborators)),\n",
    "    \"generated_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open('taylor_summary.json', 'w') as jsonfile:\n",
    "    json.dump(summary, jsonfile, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Created taylor_summary.json\")\n",
    "print(f\"Summary: {summary['total_tracks']} tracks across {summary['total_albums']} albums, {summary['total_sales']}M sales\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Path Operations\n",
    "\n",
    "Handle file paths safely across different operating systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "print(\"=== File Path Operations ===\")\n",
    "\n",
    "# Using pathlib (modern approach)\n",
    "data_dir = Path(\"taylor_swift_data\")\n",
    "albums_dir = data_dir / \"albums\"\n",
    "songs_dir = data_dir / \"songs\"\n",
    "\n",
    "# Create directory structure\n",
    "albums_dir.mkdir(parents=True, exist_ok=True)\n",
    "songs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Created directory structure:\")\n",
    "print(f\"  {data_dir}\")\n",
    "print(f\"  {albums_dir}\")\n",
    "print(f\"  {songs_dir}\")\n",
    "\n",
    "# Create sample files in different directories\n",
    "album_files = [\n",
    "    (\"folklore.json\", {\"title\": \"folklore\", \"year\": 2020, \"genre\": \"Alternative\"}),\n",
    "    (\"midnights.json\", {\"title\": \"Midnights\", \"year\": 2022, \"genre\": \"Pop\"}),\n",
    "    (\"1989.json\", {\"title\": \"1989\", \"year\": 2014, \"genre\": \"Pop\"})\n",
    "]\n",
    "\n",
    "for filename, data in album_files:\n",
    "    file_path = albums_dir / filename\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"‚úì Created {file_path}\")\n",
    "\n",
    "# Create song files\n",
    "song_files = [\n",
    "    \"cardigan.txt\",\n",
    "    \"anti_hero.txt\", \n",
    "    \"shake_it_off.txt\",\n",
    "    \"love_story.txt\"\n",
    "]\n",
    "\n",
    "for song_file in song_files:\n",
    "    file_path = songs_dir / song_file\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(f\"Song data for {song_file.replace('_', ' ').replace('.txt', '')}\")\n",
    "    print(f\"‚úì Created {file_path}\")\n",
    "\n",
    "print(\"\\n=== File Discovery ===\")\n",
    "\n",
    "# List all files in directory\n",
    "print(f\"Files in {albums_dir}:\")\n",
    "for file_path in albums_dir.iterdir():\n",
    "    if file_path.is_file():\n",
    "        print(f\"  {file_path.name} ({file_path.stat().st_size} bytes)\")\n",
    "\n",
    "# Use glob patterns\n",
    "print(f\"\\nJSON files in album directory:\")\n",
    "json_files = list(albums_dir.glob(\"*.json\"))\n",
    "for json_file in json_files:\n",
    "    print(f\"  {json_file.name}\")\n",
    "\n",
    "# Recursive file search\n",
    "print(f\"\\nAll .txt files in data directory (recursive):\")\n",
    "txt_files = list(data_dir.glob(\"**/*.txt\"))\n",
    "for txt_file in txt_files:\n",
    "    relative_path = txt_file.relative_to(data_dir)\n",
    "    print(f\"  {relative_path}\")\n",
    "\n",
    "print(\"\\n=== File Information ===\")\n",
    "\n",
    "# Get file information\n",
    "for json_file in json_files:\n",
    "    stat = json_file.stat()\n",
    "    print(f\"\\n{json_file.name}:\")\n",
    "    print(f\"  Size: {stat.st_size} bytes\")\n",
    "    print(f\"  Modified: {datetime.fromtimestamp(stat.st_mtime)}\")\n",
    "    print(f\"  Exists: {json_file.exists()}\")\n",
    "    print(f\"  Is file: {json_file.is_file()}\")\n",
    "    print(f\"  Suffix: {json_file.suffix}\")\n",
    "    print(f\"  Stem: {json_file.stem}\")\n",
    "\n",
    "# Working with file paths\n",
    "sample_path = albums_dir / \"folklore.json\"\n",
    "print(f\"\\nPath analysis for {sample_path}:\")\n",
    "print(f\"  Parent directory: {sample_path.parent}\")\n",
    "print(f\"  Absolute path: {sample_path.absolute()}\")\n",
    "print(f\"  Parts: {sample_path.parts}\")\n",
    "\n",
    "# Check if files exist before operations\n",
    "print(\"\\n=== Safe File Operations ===\")\n",
    "\n",
    "def safe_read_json(file_path):\n",
    "    \"\"\"Safely read JSON file with error handling.\"\"\"\n",
    "    try:\n",
    "        if not file_path.exists():\n",
    "            print(f\"Warning: {file_path} does not exist\")\n",
    "            return None\n",
    "        \n",
    "        if not file_path.is_file():\n",
    "            print(f\"Warning: {file_path} is not a file\")\n",
    "            return None\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON in {file_path}: {e}\")\n",
    "        return None\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied reading {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Test safe reading\n",
    "for json_file in json_files:\n",
    "    data = safe_read_json(json_file)\n",
    "    if data:\n",
    "        print(f\"‚úì Successfully read {json_file.name}: {data.get('title', 'Unknown')}\")\n",
    "\n",
    "# Clean up - remove created files and directories\n",
    "print(\"\\n=== Cleanup ===\")\n",
    "\n",
    "def cleanup_directory(dir_path):\n",
    "    \"\"\"Remove all files and subdirectories.\"\"\"\n",
    "    if not dir_path.exists():\n",
    "        return\n",
    "    \n",
    "    for item in dir_path.iterdir():\n",
    "        if item.is_file():\n",
    "            item.unlink()\n",
    "            print(f\"  Removed file: {item.name}\")\n",
    "        elif item.is_dir():\n",
    "            cleanup_directory(item)\n",
    "            item.rmdir()\n",
    "            print(f\"  Removed directory: {item.name}\")\n",
    "\n",
    "# Uncomment to clean up created files\n",
    "# cleanup_directory(data_dir)\n",
    "# data_dir.rmdir()\n",
    "# print(f\"‚úì Cleaned up {data_dir}\")\n",
    "\n",
    "print(f\"Directory structure preserved for inspection\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling with Files\n",
    "\n",
    "Handle common file operation errors gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def robust_file_reader(file_path, file_type='text'):\n",
    "    \"\"\"\n",
    "    Robust file reader with comprehensive error handling.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to file (string or Path object)\n",
    "        file_type: 'text', 'json', or 'csv'\n",
    "    \n",
    "    Returns:\n",
    "        File content or None if error\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to Path object\n",
    "    path = Path(file_path)\n",
    "    \n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not path.exists():\n",
    "            print(f\"‚ùå File not found: {path}\")\n",
    "            return None\n",
    "        \n",
    "        # Check if it's actually a file\n",
    "        if not path.is_file():\n",
    "            print(f\"‚ùå Path is not a file: {path}\")\n",
    "            return None\n",
    "        \n",
    "        # Check file size\n",
    "        file_size = path.stat().st_size\n",
    "        if file_size == 0:\n",
    "            print(f\"‚ö†Ô∏è File is empty: {path}\")\n",
    "            return None\n",
    "        \n",
    "        if file_size > 10_000_000:  # 10MB limit\n",
    "            print(f\"‚ö†Ô∏è File is very large ({file_size:,} bytes): {path}\")\n",
    "            user_input = input(\"Continue? (y/n): \")\n",
    "            if user_input.lower() != 'y':\n",
    "                return None\n",
    "        \n",
    "        # Read file based on type\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            if file_type == 'json':\n",
    "                return json.load(file)\n",
    "            elif file_type == 'csv':\n",
    "                import csv\n",
    "                return list(csv.reader(file))\n",
    "            else:  # text\n",
    "                return file.read()\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found: {path}\")\n",
    "        return None\n",
    "    \n",
    "    except PermissionError:\n",
    "        print(f\"‚ùå Permission denied: {path}\")\n",
    "        return None\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå Invalid JSON in {path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"‚ùå Encoding error in {path}: {e}\")\n",
    "        print(\"Try opening with different encoding\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error reading {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def robust_file_writer(file_path, content, file_type='text', backup=True):\n",
    "    \"\"\"\n",
    "    Robust file writer with backup and error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    path = Path(file_path)\n",
    "    \n",
    "    try:\n",
    "        # Create backup if file exists\n",
    "        if backup and path.exists():\n",
    "            backup_path = path.with_suffix(path.suffix + '.backup')\n",
    "            path.rename(backup_path)\n",
    "            print(f\"‚úì Created backup: {backup_path}\")\n",
    "        \n",
    "        # Create parent directories if needed\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Write file based on type\n",
    "        with open(path, 'w', encoding='utf-8') as file:\n",
    "            if file_type == 'json':\n",
    "                json.dump(content, file, indent=2)\n",
    "            elif file_type == 'csv':\n",
    "                import csv\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(content)\n",
    "            else:  # text\n",
    "                file.write(content)\n",
    "        \n",
    "        print(f\"‚úì Successfully wrote: {path}\")\n",
    "        return True\n",
    "    \n",
    "    except PermissionError:\n",
    "        print(f\"‚ùå Permission denied writing to: {path}\")\n",
    "        return False\n",
    "    \n",
    "    except OSError as e:\n",
    "        print(f\"‚ùå OS error writing to {path}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error writing to {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=== Testing Robust File Operations ===\")\n",
    "\n",
    "# Test reading existing file\n",
    "content = robust_file_reader('taylor_albums.csv', 'csv')\n",
    "if content:\n",
    "    print(f\"‚úì Read CSV with {len(content)} rows\")\n",
    "\n",
    "# Test reading non-existent file\n",
    "content = robust_file_reader('nonexistent.json', 'json')\n",
    "\n",
    "# Test writing with backup\n",
    "test_data = {\n",
    "    \"song\": \"Love Story\",\n",
    "    \"album\": \"Fearless\",\n",
    "    \"year\": 2008\n",
    "}\n",
    "\n",
    "success = robust_file_writer('test_song.json', test_data, 'json')\n",
    "if success:\n",
    "    # Test reading it back\n",
    "    read_data = robust_file_reader('test_song.json', 'json')\n",
    "    if read_data:\n",
    "        print(f\"‚úì Read back: {read_data['song']} from {read_data['album']}\")\n",
    "\n",
    "# Test creating file in subdirectory\n",
    "success = robust_file_writer('data/songs/love_story.json', test_data, 'json')\n",
    "\n",
    "# Demonstrate file validation\n",
    "def validate_taylor_album_file(file_path):\n",
    "    \"\"\"\n",
    "    Validate Taylor Swift album JSON file structure.\n",
    "    \"\"\"\n",
    "    data = robust_file_reader(file_path, 'json')\n",
    "    if not data:\n",
    "        return False\n",
    "    \n",
    "    required_fields = ['title', 'year', 'genre']\n",
    "    \n",
    "    for field in required_fields:\n",
    "        if field not in data:\n",
    "            print(f\"‚ùå Missing required field: {field}\")\n",
    "            return False\n",
    "    \n",
    "    # Validate data types\n",
    "    if not isinstance(data['year'], int):\n",
    "        print(f\"‚ùå Year must be an integer, got {type(data['year'])}\")\n",
    "        return False\n",
    "    \n",
    "    if data['year'] < 2000 or data['year'] > 2030:\n",
    "        print(f\"‚ùå Year {data['year']} seems unrealistic\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"‚úì Valid album file: {data['title']} ({data['year']})\")\n",
    "    return True\n",
    "\n",
    "# Test validation\n",
    "if Path('taylor_swift_data/albums/folklore.json').exists():\n",
    "    validate_taylor_album_file('taylor_swift_data/albums/folklore.json')\n",
    "\n",
    "# Create invalid file for testing\n",
    "invalid_data = {\"title\": \"Test Album\", \"invalid_year\": \"not a number\"}\n",
    "robust_file_writer('invalid_album.json', invalid_data, 'json')\n",
    "validate_taylor_album_file('invalid_album.json')\n",
    "\n",
    "print(\"\\n=== File Operation Summary ===\")\n",
    "print(\"‚úì Demonstrated robust error handling\")\n",
    "print(\"‚úì Showed backup creation\")\n",
    "print(\"‚úì Validated file structure\")\n",
    "print(\"‚úì Handled various error conditions\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Time! üéµ\n",
    "\n",
    "Let's practice file operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Practice Exercise 1:\n",
    "# Create a function that reads a CSV file of song data and:\n",
    "# 1. Calculates the total duration of all songs\n",
    "# 2. Finds the longest and shortest songs\n",
    "# 3. Groups songs by genre\n",
    "# 4. Writes the results to a JSON summary file\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Sample CSV data to work with\n",
    "sample_songs = [\n",
    "    ['Title', 'Album', 'Duration_Seconds', 'Genre'],\n",
    "    ['Love Story', 'Fearless', 213, 'Country'],\n",
    "    ['Shake It Off', '1989', 203, 'Pop'],\n",
    "    ['cardigan', 'folklore', 219, 'Alternative'],\n",
    "    ['Anti-Hero', 'Midnights', 200, 'Pop'],\n",
    "    ['All Too Well', 'Red', 329, 'Country']\n",
    "]\n",
    "\n",
    "# Create sample CSV file\n",
    "with open('sample_songs.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(sample_songs)\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Practice Exercise 2:\n",
    "# Create a playlist manager that:\n",
    "# 1. Saves playlists as JSON files\n",
    "# 2. Loads existing playlists\n",
    "# 3. Merges multiple playlists\n",
    "# 4. Creates backup copies\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class PlaylistManager:\n",
    "    def __init__(self, playlist_dir=\"playlists\"):\n",
    "        self.playlist_dir = Path(playlist_dir)\n",
    "        self.playlist_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Your methods here:\n",
    "    # def save_playlist(self, name, songs):\n",
    "    # def load_playlist(self, name):\n",
    "    # def merge_playlists(self, playlist_names, new_name):\n",
    "    # def backup_playlist(self, name):\n",
    "\n",
    "# Test your playlist manager\n",
    "# manager = PlaylistManager()\n",
    "# manager.save_playlist(\"favorites\", [\"Love Story\", \"Shake It Off\", \"cardigan\"])\n",
    "# loaded = manager.load_playlist(\"favorites\")\n",
    "# print(f\"Loaded playlist: {loaded}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Practice Exercise 3:\n",
    "# Create a data processor that:\n",
    "# 1. Reads multiple JSON files from a directory\n",
    "# 2. Validates the data structure\n",
    "# 3. Combines them into a master dataset\n",
    "# 4. Exports the combined data in multiple formats (JSON, CSV)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "\n",
    "class TaylorDataProcessor:\n",
    "    def __init__(self, data_dir=\"taylor_data\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    # Your methods here:\n",
    "    # def validate_album_data(self, data):\n",
    "    # def read_all_albums(self):\n",
    "    # def combine_data(self, album_list):\n",
    "    # def export_to_csv(self, combined_data, filename):\n",
    "    # def export_to_json(self, combined_data, filename):\n",
    "\n",
    "# Test your data processor\n",
    "# processor = TaylorDataProcessor()\n",
    "# albums = processor.read_all_albums()\n",
    "# combined = processor.combine_data(albums)\n",
    "# processor.export_to_csv(combined, \"all_albums.csv\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example: Music Library Manager\n",
    "\n",
    "Build a complete file-based music library system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "import shutil\n",
    "\n",
    "class TaylorSwiftLibraryManager:\n",
    "    \"\"\"\n",
    "    Complete file-based music library management system.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, library_path=\"taylor_library\"):\n",
    "        self.library_path = Path(library_path)\n",
    "        self.albums_path = self.library_path / \"albums\"\n",
    "        self.playlists_path = self.library_path / \"playlists\"\n",
    "        self.exports_path = self.library_path / \"exports\"\n",
    "        self.backups_path = self.library_path / \"backups\"\n",
    "        \n",
    "        # Create directory structure\n",
    "        for path in [self.albums_path, self.playlists_path, self.exports_path, self.backups_path]:\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.library_index = self._load_or_create_index()\n",
    "    \n",
    "    def _load_or_create_index(self):\n",
    "        \"\"\"Load or create the main library index.\"\"\"\n",
    "        index_path = self.library_path / \"library_index.json\"\n",
    "        \n",
    "        if index_path.exists():\n",
    "            try:\n",
    "                with open(index_path, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                pass\n",
    "        \n",
    "        # Create new index\n",
    "        return {\n",
    "            \"created\": datetime.now().isoformat(),\n",
    "            \"last_updated\": datetime.now().isoformat(),\n",
    "            \"version\": \"1.0\",\n",
    "            \"albums\": {},\n",
    "            \"playlists\": {},\n",
    "            \"statistics\": {\n",
    "                \"total_albums\": 0,\n",
    "                \"total_songs\": 0,\n",
    "                \"total_duration_seconds\": 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def save_index(self):\n",
    "        \"\"\"Save the library index.\"\"\"\n",
    "        self.library_index[\"last_updated\"] = datetime.now().isoformat()\n",
    "        index_path = self.library_path / \"library_index.json\"\n",
    "        \n",
    "        with open(index_path, 'w') as f:\n",
    "            json.dump(self.library_index, f, indent=2)\n",
    "    \n",
    "    def add_album(self, album_data):\n",
    "        \"\"\"Add an album to the library.\"\"\"\n",
    "        required_fields = ['title', 'year', 'genre', 'tracks']\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field not in album_data:\n",
    "                raise ValueError(f\"Missing required field: {field}\")\n",
    "        \n",
    "        # Validate tracks\n",
    "        if not isinstance(album_data['tracks'], list):\n",
    "            raise ValueError(\"Tracks must be a list\")\n",
    "        \n",
    "        for track in album_data['tracks']:\n",
    "            if not isinstance(track, dict) or 'title' not in track:\n",
    "                raise ValueError(\"Each track must be a dict with 'title'\")\n",
    "        \n",
    "        # Generate file name\n",
    "        album_id = album_data['title'].lower().replace(' ', '_').replace(\"'\", \"\")\n",
    "        album_file = self.albums_path / f\"{album_id}.json\"\n",
    "        \n",
    "        # Add metadata\n",
    "        album_data['id'] = album_id\n",
    "        album_data['added_date'] = datetime.now().isoformat()\n",
    "        album_data['file_path'] = str(album_file)\n",
    "        \n",
    "        # Save album file\n",
    "        with open(album_file, 'w') as f:\n",
    "            json.dump(album_data, f, indent=2)\n",
    "        \n",
    "        # Update index\n",
    "        self.library_index['albums'][album_id] = {\n",
    "            'title': album_data['title'],\n",
    "            'year': album_data['year'],\n",
    "            'genre': album_data['genre'],\n",
    "            'track_count': len(album_data['tracks']),\n",
    "            'file_path': str(album_file),\n",
    "            'added_date': album_data['added_date']\n",
    "        }\n",
    "        \n",
    "        # Update statistics\n",
    "        stats = self.library_index['statistics']\n",
    "        stats['total_albums'] = len(self.library_index['albums'])\n",
    "        stats['total_songs'] = sum(album['track_count'] for album in self.library_index['albums'].values())\n",
    "        \n",
    "        self.save_index()\n",
    "        print(f\"‚úì Added album: {album_data['title']} ({len(album_data['tracks'])} tracks)\")\n",
    "        \n",
    "        return album_id\n",
    "    \n",
    "    def get_album(self, album_id):\n",
    "        \"\"\"Get full album data.\"\"\"\n",
    "        if album_id not in self.library_index['albums']:\n",
    "            return None\n",
    "        \n",
    "        album_file = Path(self.library_index['albums'][album_id]['file_path'])\n",
    "        if not album_file.exists():\n",
    "            print(f\"Warning: Album file missing: {album_file}\")\n",
    "            return None\n",
    "        \n",
    "        with open(album_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def create_playlist(self, name, song_criteria=None, album_criteria=None):\n",
    "        \"\"\"Create a playlist based on criteria.\"\"\"\n",
    "        playlist_songs = []\n",
    "        \n",
    "        for album_id in self.library_index['albums']:\n",
    "            album = self.get_album(album_id)\n",
    "            if not album:\n",
    "                continue\n",
    "            \n",
    "            # Check album criteria\n",
    "            if album_criteria:\n",
    "                if 'genre' in album_criteria and album['genre'] not in album_criteria['genre']:\n",
    "                    continue\n",
    "                if 'min_year' in album_criteria and album['year'] < album_criteria['min_year']:\n",
    "                    continue\n",
    "                if 'max_year' in album_criteria and album['year'] > album_criteria['max_year']:\n",
    "                    continue\n",
    "            \n",
    "            # Add qualifying songs\n",
    "            for track in album['tracks']:\n",
    "                song_entry = {\n",
    "                    'title': track['title'],\n",
    "                    'album': album['title'],\n",
    "                    'year': album['year'],\n",
    "                    'genre': album['genre'],\n",
    "                    'duration': track.get('duration', 0)\n",
    "                }\n",
    "                \n",
    "                # Check song criteria\n",
    "                if song_criteria:\n",
    "                    if 'min_duration' in song_criteria and song_entry['duration'] < song_criteria['min_duration']:\n",
    "                        continue\n",
    "                    if 'max_duration' in song_criteria and song_entry['duration'] > song_criteria['max_duration']:\n",
    "                        continue\n",
    "                    if 'title_contains' in song_criteria:\n",
    "                        if song_criteria['title_contains'].lower() not in track['title'].lower():\n",
    "                            continue\n",
    "                \n",
    "                playlist_songs.append(song_entry)\n",
    "        \n",
    "        # Create playlist data\n",
    "        playlist_data = {\n",
    "            'name': name,\n",
    "            'created': datetime.now().isoformat(),\n",
    "            'song_count': len(playlist_songs),\n",
    "            'total_duration': sum(song['duration'] for song in playlist_songs),\n",
    "            'criteria': {\n",
    "                'song_criteria': song_criteria,\n",
    "                'album_criteria': album_criteria\n",
    "            },\n",
    "            'songs': playlist_songs\n",
    "        }\n",
    "        \n",
    "        # Save playlist\n",
    "        playlist_id = name.lower().replace(' ', '_')\n",
    "        playlist_file = self.playlists_path / f\"{playlist_id}.json\"\n",
    "        \n",
    "        with open(playlist_file, 'w') as f:\n",
    "            json.dump(playlist_data, f, indent=2)\n",
    "        \n",
    "        # Update index\n",
    "        self.library_index['playlists'][playlist_id] = {\n",
    "            'name': name,\n",
    "            'song_count': len(playlist_songs),\n",
    "            'created': playlist_data['created'],\n",
    "            'file_path': str(playlist_file)\n",
    "        }\n",
    "        \n",
    "        self.save_index()\n",
    "        print(f\"‚úì Created playlist '{name}' with {len(playlist_songs)} songs\")\n",
    "        \n",
    "        return playlist_id\n",
    "    \n",
    "    def export_library_report(self, format='json'):\n",
    "        \"\"\"Export comprehensive library report.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Gather all data\n",
    "        report_data = {\n",
    "            'generated': datetime.now().isoformat(),\n",
    "            'library_stats': self.library_index['statistics'].copy(),\n",
    "            'albums': [],\n",
    "            'playlists': list(self.library_index['playlists'].values())\n",
    "        }\n",
    "        \n",
    "        # Add detailed album info\n",
    "        for album_id in self.library_index['albums']:\n",
    "            album = self.get_album(album_id)\n",
    "            if album:\n",
    "                report_data['albums'].append({\n",
    "                    'title': album['title'],\n",
    "                    'year': album['year'],\n",
    "                    'genre': album['genre'],\n",
    "                    'track_count': len(album['tracks']),\n",
    "                    'tracks': [track['title'] for track in album['tracks']]\n",
    "                })\n",
    "        \n",
    "        if format == 'json':\n",
    "            report_file = self.exports_path / f\"library_report_{timestamp}.json\"\n",
    "            with open(report_file, 'w') as f:\n",
    "                json.dump(report_data, f, indent=2)\n",
    "        \n",
    "        elif format == 'csv':\n",
    "            report_file = self.exports_path / f\"library_report_{timestamp}.csv\"\n",
    "            with open(report_file, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['Album', 'Year', 'Genre', 'Track_Count', 'Track_List'])\n",
    "                for album in report_data['albums']:\n",
    "                    tracks_str = '; '.join(album['tracks'])\n",
    "                    writer.writerow([album['title'], album['year'], album['genre'], \n",
    "                                   album['track_count'], tracks_str])\n",
    "        \n",
    "        print(f\"‚úì Exported library report: {report_file}\")\n",
    "        return report_file\n",
    "    \n",
    "    def backup_library(self):\n",
    "        \"\"\"Create a backup of the entire library.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_dir = self.backups_path / f\"backup_{timestamp}\"\n",
    "        \n",
    "        # Copy entire library\n",
    "        shutil.copytree(self.library_path, backup_dir, \n",
    "                       ignore=shutil.ignore_patterns('backups'))\n",
    "        \n",
    "        print(f\"‚úì Created backup: {backup_dir}\")\n",
    "        return backup_dir\n",
    "    \n",
    "    def get_library_stats(self):\n",
    "        \"\"\"Get current library statistics.\"\"\"\n",
    "        stats = self.library_index['statistics'].copy()\n",
    "        \n",
    "        # Calculate additional stats\n",
    "        genres = {}\n",
    "        years = []\n",
    "        \n",
    "        for album_info in self.library_index['albums'].values():\n",
    "            genre = album_info['genre']\n",
    "            genres[genre] = genres.get(genre, 0) + 1\n",
    "            years.append(album_info['year'])\n",
    "        \n",
    "        stats['genres'] = genres\n",
    "        stats['year_range'] = f\"{min(years) if years else 'N/A'} - {max(years) if years else 'N/A'}\"\n",
    "        stats['playlists_count'] = len(self.library_index['playlists'])\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Create and test the library manager\n",
    "print(\"üéµ TAYLOR SWIFT LIBRARY MANAGER üéµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "library = TaylorSwiftLibraryManager()\n",
    "\n",
    "# Add sample albums\n",
    "sample_albums = [\n",
    "    {\n",
    "        \"title\": \"folklore\",\n",
    "        \"year\": 2020,\n",
    "        \"genre\": \"Alternative\",\n",
    "        \"tracks\": [\n",
    "            {\"title\": \"the 1\", \"duration\": 210},\n",
    "            {\"title\": \"cardigan\", \"duration\": 219},\n",
    "            {\"title\": \"the last great american dynasty\", \"duration\": 231}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Midnights\", \n",
    "        \"year\": 2022,\n",
    "        \"genre\": \"Pop\",\n",
    "        \"tracks\": [\n",
    "            {\"title\": \"Lavender Haze\", \"duration\": 202},\n",
    "            {\"title\": \"Anti-Hero\", \"duration\": 200},\n",
    "            {\"title\": \"Midnight Rain\", \"duration\": 174}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add albums to library\n",
    "for album in sample_albums:\n",
    "    library.add_album(album)\n",
    "\n",
    "# Create playlists\n",
    "library.create_playlist(\"Recent Favorites\", \n",
    "                       album_criteria={'min_year': 2020})\n",
    "\n",
    "library.create_playlist(\"Short Songs\", \n",
    "                       song_criteria={'max_duration': 210})\n",
    "\n",
    "# Get and display statistics\n",
    "stats = library.get_library_stats()\n",
    "print(f\"\\nüìä LIBRARY STATISTICS:\")\n",
    "print(f\"   Total Albums: {stats['total_albums']}\")\n",
    "print(f\"   Total Songs: {stats['total_songs']}\")\n",
    "print(f\"   Playlists: {stats['playlists_count']}\")\n",
    "print(f\"   Year Range: {stats['year_range']}\")\n",
    "print(f\"   Genres: {', '.join(stats['genres'].keys())}\")\n",
    "\n",
    "# Export reports\n",
    "json_report = library.export_library_report('json')\n",
    "csv_report = library.export_library_report('csv')\n",
    "\n",
    "# Create backup\n",
    "backup_path = library.backup_library()\n",
    "\n",
    "print(f\"\\n‚úì Library management system operational!\")\n",
    "print(f\"‚úì Library path: {library.library_path}\")\n",
    "print(f\"‚úì Backup created: {backup_path.name}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### File Operations Fundamentals\n",
    "- **Always use context managers**: `with open(file, mode) as f:` ensures proper file closure\n",
    "- **Text modes**: `'r'` (read), `'w'` (write), `'a'` (append), `'x'` (exclusive creation)\n",
    "- **Encoding**: Specify `encoding='utf-8'` for text files to avoid encoding issues\n",
    "- **Binary modes**: Add `'b'` for binary files: `'rb'`, `'wb'`\n",
    "\n",
    "### CSV Handling\n",
    "- **csv.reader()**: Read CSV data row by row\n",
    "- **csv.DictReader()**: Read CSV with column headers as dictionary keys\n",
    "- **csv.writer()**: Write CSV data\n",
    "- **Custom delimiters**: Use `delimiter='|'` or other separators\n",
    "- **Handle newlines**: Use `newline=''` when opening CSV files for writing\n",
    "\n",
    "### JSON Operations\n",
    "- **json.load()**: Read JSON from file\n",
    "- **json.dump()**: Write JSON to file\n",
    "- **json.loads()**: Parse JSON string\n",
    "- **json.dumps()**: Convert to JSON string\n",
    "- **Pretty formatting**: Use `indent=2` for readable JSON\n",
    "- **Compact formatting**: Use `separators=(',', ':')` for minimal size\n",
    "\n",
    "### Path Operations (pathlib)\n",
    "- **Path creation**: `Path('directory') / 'file.txt'`\n",
    "- **Directory creation**: `path.mkdir(parents=True, exist_ok=True)`\n",
    "- **File existence**: `path.exists()`, `path.is_file()`, `path.is_dir()`\n",
    "- **File info**: `path.stat()`, `path.suffix`, `path.stem`\n",
    "- **Glob patterns**: `path.glob('*.json')`, `path.glob('**/*.txt')`\n",
    "\n",
    "### Error Handling Best Practices\n",
    "- **Check existence**: Always verify files exist before reading\n",
    "- **Handle specific exceptions**: `FileNotFoundError`, `PermissionError`, `JSONDecodeError`\n",
    "- **Validate data**: Check file structure and content validity\n",
    "- **Create backups**: Before modifying important files\n",
    "- **Use try-except**: Wrap file operations in error handling\n",
    "\n",
    "### File Organization Strategies\n",
    "- **Directory structure**: Organize files logically (`data/albums/`, `exports/`, `backups/`)\n",
    "- **Naming conventions**: Use consistent, descriptive file names\n",
    "- **Index files**: Maintain metadata files for complex data structures\n",
    "- **Versioning**: Include timestamps or version numbers in file names\n",
    "- **Separation of concerns**: Keep different data types in separate files/directories\n",
    "\n",
    "### Performance Considerations\n",
    "- **Stream large files**: Use line-by-line reading for large files\n",
    "- **Batch operations**: Group multiple file operations together\n",
    "- **Avoid repeated file access**: Cache frequently accessed data\n",
    "- **Use appropriate data formats**: JSON for structure, CSV for tabular data\n",
    "\n",
    "### Security and Safety\n",
    "- **Validate input**: Never trust file paths from user input\n",
    "- **Set file permissions**: Restrict access to sensitive files\n",
    "- **Backup before modification**: Always create backups of important data\n",
    "- **Handle encoding properly**: Specify encoding explicitly\n",
    "- **Sanitize file names**: Remove or escape special characters\n",
    "\n",
    "Next up: Errors & Exceptions - where we'll learn to handle problems gracefully! üé§"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}