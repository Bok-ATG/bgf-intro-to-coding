{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taylor Swift Python Tutorial: Errors & Exceptions\n",
    "\n",
    "Learn to handle errors gracefully in your Taylor Swift data programs! Understanding exceptions and error handling is crucial for building robust applications that can deal with unexpected situations.\n",
    "\n",
    "## Learning Goals\n",
    "- Understand different **types of errors** and exceptions\n",
    "- Master **try/except** blocks for error handling\n",
    "- Use **else** and **finally** clauses effectively\n",
    "- Learn to **raise custom exceptions**\n",
    "- Build **robust error handling** for music data processing\n",
    "- Practice **debugging** techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Python Exceptions\n",
    "\n",
    "Let's explore common exceptions with Taylor Swift examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Common exceptions in Taylor Swift data processing\n",
    "\n",
    "taylor_albums = [\"Taylor Swift\", \"Fearless\", \"Speak Now\", \"Red\", \"1989\"]\n",
    "album_years = {\"Fearless\": 2008, \"1989\": 2014, \"folklore\": 2020}\n",
    "song_durations = [\"3:55\", \"3:39\", \"4:02\", \"invalid\"]\n",
    "\n",
    "print(\"=== Common Exception Types ===\")\n",
    "\n",
    "# 1. IndexError - accessing invalid list index\n",
    "print(\"\\n1. IndexError Example:\")\n",
    "try:\n",
    "    print(f\"Album at index 5: {taylor_albums[5]}\")\n",
    "except IndexError as e:\n",
    "    print(f\"❌ IndexError: {e}\")\n",
    "    print(f\"   Available albums: {len(taylor_albums)} (indices 0-{len(taylor_albums)-1})\")\n",
    "\n",
    "# 2. KeyError - accessing invalid dictionary key\n",
    "print(\"\\n2. KeyError Example:\")\n",
    "try:\n",
    "    year = album_years[\"reputation\"]\n",
    "    print(f\"reputation released in {year}\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ KeyError: {e}\")\n",
    "    print(f\"   Available albums: {list(album_years.keys())}\")\n",
    "\n",
    "# 3. ValueError - invalid value for operation\n",
    "print(\"\\n3. ValueError Example:\")\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"Parse duration string like '3:55' to seconds.\"\"\"\n",
    "    parts = duration_str.split(':')\n",
    "    minutes = int(parts[0])\n",
    "    seconds = int(parts[1])\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "for duration in song_durations:\n",
    "    try:\n",
    "        total_seconds = parse_duration(duration)\n",
    "        print(f\"✓ {duration} = {total_seconds} seconds\")\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ ValueError with '{duration}': {e}\")\n",
    "    except IndexError as e:\n",
    "        print(f\"❌ IndexError with '{duration}': {e}\")\n",
    "\n",
    "# 4. TypeError - wrong type for operation\n",
    "print(\"\\n4. TypeError Example:\")\n",
    "try:\n",
    "    result = \"folklore\" + 2020\n",
    "except TypeError as e:\n",
    "    print(f\"❌ TypeError: {e}\")\n",
    "    print(f\"   Correct: 'folklore' + str(2020) = {'folklore' + str(2020)}\")\n",
    "\n",
    "# 5. AttributeError - accessing non-existent attribute\n",
    "print(\"\\n5. AttributeError Example:\")\n",
    "song_title = \"Love Story\"\n",
    "try:\n",
    "    uppercase = song_title.to_upper()  # Wrong method name\n",
    "except AttributeError as e:\n",
    "    print(f\"❌ AttributeError: {e}\")\n",
    "    print(f\"   Correct method: .upper() = {song_title.upper()}\")\n",
    "\n",
    "# 6. ZeroDivisionError - division by zero\n",
    "print(\"\\n6. ZeroDivisionError Example:\")\n",
    "total_streams = 1000000\n",
    "album_count = 0  # Oops, no albums processed yet\n",
    "\n",
    "try:\n",
    "    avg_streams = total_streams / album_count\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"❌ ZeroDivisionError: {e}\")\n",
    "    print(f\"   Cannot calculate average with 0 albums\")\n",
    "\n",
    "print(\"\\n✓ Exception overview complete!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Try/Except Blocks\n",
    "\n",
    "Handle errors gracefully in Taylor Swift data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Taylor Swift song data processing with error handling\n",
    "\n",
    "song_data = [\n",
    "    {\"title\": \"Love Story\", \"streams\": \"500000000\", \"duration\": \"3:55\"},\n",
    "    {\"title\": \"Shake It Off\", \"streams\": \"800000000\", \"duration\": \"3:39\"},\n",
    "    {\"title\": \"Anti-Hero\", \"streams\": \"1200000000\", \"duration\": \"3:20\"},\n",
    "    {\"title\": \"cardigan\", \"streams\": \"not_a_number\", \"duration\": \"3:59\"},\n",
    "    {\"title\": \"All Too Well\", \"streams\": \"600000000\", \"duration\": \"5:29\"},\n",
    "    {\"title\": \"Bad Song\", \"streams\": \"300000000\"},  # Missing duration\n",
    "]\n",
    "\n",
    "print(\"=== Processing Song Data with Error Handling ===\")\n",
    "\n",
    "def safe_process_song(song):\n",
    "    \"\"\"Safely process a song dictionary with error handling.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Extract basic info\n",
    "        title = song[\"title\"]\n",
    "        \n",
    "        # Convert streams to integer\n",
    "        streams = int(song[\"streams\"])\n",
    "        \n",
    "        # Parse duration\n",
    "        duration_str = song[\"duration\"]\n",
    "        minutes, seconds = duration_str.split(':')\n",
    "        duration_seconds = int(minutes) * 60 + int(seconds)\n",
    "        \n",
    "        # Calculate streams per second of song\n",
    "        streams_per_second = streams / duration_seconds\n",
    "        \n",
    "        result = {\n",
    "            \"title\": title,\n",
    "            \"streams\": streams,\n",
    "            \"duration_seconds\": duration_seconds,\n",
    "            \"streams_per_second\": streams_per_second,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ {title}: {streams:,} streams, {streams_per_second:,.0f} streams/sec\")\n",
    "        return result\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"❌ Missing field in {song.get('title', 'Unknown')}: {e}\")\n",
    "        return {\"title\": song.get(\"title\", \"Unknown\"), \"status\": \"missing_field\", \"error\": str(e)}\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Invalid data in {song.get('title', 'Unknown')}: {e}\")\n",
    "        return {\"title\": song.get(\"title\", \"Unknown\"), \"status\": \"invalid_data\", \"error\": str(e)}\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        print(f\"❌ Zero duration in {song.get('title', 'Unknown')}\")\n",
    "        return {\"title\": song.get(\"title\", \"Unknown\"), \"status\": \"zero_duration\", \"error\": \"Duration is zero\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error in {song.get('title', 'Unknown')}: {e}\")\n",
    "        return {\"title\": song.get(\"title\", \"Unknown\"), \"status\": \"unexpected_error\", \"error\": str(e)}\n",
    "\n",
    "# Process all songs\n",
    "processed_songs = []\n",
    "for song in song_data:\n",
    "    result = safe_process_song(song)\n",
    "    processed_songs.append(result)\n",
    "\n",
    "# Analyze results\n",
    "successful = [s for s in processed_songs if s[\"status\"] == \"success\"]\n",
    "failed = [s for s in processed_songs if s[\"status\"] != \"success\"]\n",
    "\n",
    "print(f\"\\n=== Processing Summary ===\")\n",
    "print(f\"✓ Successful: {len(successful)} songs\")\n",
    "print(f\"❌ Failed: {len(failed)} songs\")\n",
    "\n",
    "if failed:\n",
    "    print(\"\\nFailed songs:\")\n",
    "    for song in failed:\n",
    "        print(f\"  • {song['title']}: {song['status']} - {song['error']}\")\n",
    "\n",
    "if successful:\n",
    "    total_streams = sum(s[\"streams\"] for s in successful)\n",
    "    avg_streams = total_streams / len(successful)\n",
    "    print(f\"\\nSuccess metrics:\")\n",
    "    print(f\"  Total streams: {total_streams:,}\")\n",
    "    print(f\"  Average streams: {avg_streams:,.0f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Exception Handling\n",
    "\n",
    "Handle different types of errors with specific responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Advanced error handling for Taylor Swift album analysis\n",
    "\n",
    "def analyze_album_data(album_name, tracks_data):\n",
    "    \"\"\"\n",
    "    Analyze album data with comprehensive error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nAnalyzing: {album_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(tracks_data, list):\n",
    "            raise TypeError(f\"Expected list of tracks, got {type(tracks_data)}\")\n",
    "        \n",
    "        if len(tracks_data) == 0:\n",
    "            raise ValueError(\"Album has no tracks\")\n",
    "        \n",
    "        # Process tracks\n",
    "        total_duration = 0\n",
    "        valid_tracks = 0\n",
    "        track_errors = []\n",
    "        \n",
    "        for i, track in enumerate(tracks_data):\n",
    "            try:\n",
    "                # Validate track structure\n",
    "                if not isinstance(track, dict):\n",
    "                    raise TypeError(f\"Track {i+1} must be a dictionary\")\n",
    "                \n",
    "                if \"title\" not in track:\n",
    "                    raise KeyError(f\"Track {i+1} missing 'title'\")\n",
    "                \n",
    "                if \"duration\" not in track:\n",
    "                    raise KeyError(f\"Track {i+1} ('{track['title']}') missing 'duration'\")\n",
    "                \n",
    "                # Parse duration\n",
    "                duration_str = track[\"duration\"]\n",
    "                if not isinstance(duration_str, str):\n",
    "                    raise TypeError(f\"Duration must be string, got {type(duration_str)}\")\n",
    "                \n",
    "                # Convert duration to seconds\n",
    "                if \":\" not in duration_str:\n",
    "                    raise ValueError(f\"Invalid duration format: '{duration_str}' (expected 'MM:SS')\")\n",
    "                \n",
    "                parts = duration_str.split(\":\")\n",
    "                if len(parts) != 2:\n",
    "                    raise ValueError(f\"Invalid duration format: '{duration_str}' (expected 'MM:SS')\")\n",
    "                \n",
    "                minutes = int(parts[0])\n",
    "                seconds = int(parts[1])\n",
    "                \n",
    "                if minutes < 0 or seconds < 0 or seconds >= 60:\n",
    "                    raise ValueError(f\"Invalid time values: {minutes}:{seconds}\")\n",
    "                \n",
    "                track_duration = minutes * 60 + seconds\n",
    "                total_duration += track_duration\n",
    "                valid_tracks += 1\n",
    "                \n",
    "                print(f\"  ✓ {track['title']}: {duration_str} ({track_duration}s)\")\n",
    "                \n",
    "            except (KeyError, TypeError, ValueError) as e:\n",
    "                error_msg = f\"Track {i+1}: {e}\"\n",
    "                track_errors.append(error_msg)\n",
    "                print(f\"  ❌ {error_msg}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate statistics\n",
    "        if valid_tracks == 0:\n",
    "            raise ValueError(\"No valid tracks found in album\")\n",
    "        \n",
    "        avg_duration = total_duration / valid_tracks\n",
    "        total_minutes = total_duration / 60\n",
    "        \n",
    "        # Return results\n",
    "        results = {\n",
    "            \"album\": album_name,\n",
    "            \"total_tracks\": len(tracks_data),\n",
    "            \"valid_tracks\": valid_tracks,\n",
    "            \"invalid_tracks\": len(tracks_data) - valid_tracks,\n",
    "            \"total_duration_seconds\": total_duration,\n",
    "            \"total_duration_minutes\": total_minutes,\n",
    "            \"average_track_duration\": avg_duration,\n",
    "            \"errors\": track_errors\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n📊 Results:\")\n",
    "        print(f\"   Valid tracks: {valid_tracks}/{len(tracks_data)}\")\n",
    "        print(f\"   Total duration: {total_minutes:.1f} minutes\")\n",
    "        print(f\"   Average track: {avg_duration/60:.2f} minutes\")\n",
    "        \n",
    "        if track_errors:\n",
    "            print(f\"   Errors: {len(track_errors)}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except TypeError as e:\n",
    "        print(f\"❌ Type Error: {e}\")\n",
    "        return {\"album\": album_name, \"status\": \"type_error\", \"error\": str(e)}\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Value Error: {e}\")\n",
    "        return {\"album\": album_name, \"status\": \"value_error\", \"error\": str(e)}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected Error: {e}\")\n",
    "        return {\"album\": album_name, \"status\": \"unexpected_error\", \"error\": str(e)}\n",
    "\n",
    "# Test data with various error conditions\n",
    "test_albums = {\n",
    "    \"folklore\": [\n",
    "        {\"title\": \"the 1\", \"duration\": \"3:30\"},\n",
    "        {\"title\": \"cardigan\", \"duration\": \"3:59\"},\n",
    "        {\"title\": \"the last great american dynasty\", \"duration\": \"3:51\"}\n",
    "    ],\n",
    "    \"Bad Album 1\": [\n",
    "        {\"title\": \"Good Song\", \"duration\": \"3:20\"},\n",
    "        {\"title\": \"Bad Song\"},  # Missing duration\n",
    "        {\"title\": \"Another Song\", \"duration\": \"invalid_format\"}\n",
    "    ],\n",
    "    \"Bad Album 2\": \"not_a_list\",  # Wrong type\n",
    "    \"Empty Album\": [],  # No tracks\n",
    "    \"Bad Album 3\": [\n",
    "        \"not_a_dict\",  # Wrong track type\n",
    "        {\"duration\": \"3:20\"},  # Missing title\n",
    "        {\"title\": \"Negative Time\", \"duration\": \"-1:30\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== Album Analysis with Error Handling ===\")\n",
    "\n",
    "analysis_results = []\n",
    "for album_name, tracks in test_albums.items():\n",
    "    result = analyze_album_data(album_name, tracks)\n",
    "    analysis_results.append(result)\n",
    "\n",
    "# Summary of all analyses\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"FINAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "successful_analyses = [r for r in analysis_results if \"status\" not in r]\n",
    "failed_analyses = [r for r in analysis_results if \"status\" in r]\n",
    "\n",
    "print(f\"✓ Successful analyses: {len(successful_analyses)}\")\n",
    "print(f\"❌ Failed analyses: {len(failed_analyses)}\")\n",
    "\n",
    "if successful_analyses:\n",
    "    total_valid_tracks = sum(r[\"valid_tracks\"] for r in successful_analyses)\n",
    "    total_duration = sum(r[\"total_duration_minutes\"] for r in successful_analyses)\n",
    "    print(f\"\\nSuccess metrics:\")\n",
    "    print(f\"  Total valid tracks: {total_valid_tracks}\")\n",
    "    print(f\"  Total music: {total_duration:.1f} minutes\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Else and Finally Clauses\n",
    "\n",
    "Complete try/except blocks with else and finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def process_taylor_data_file(filename):\n",
    "    \"\"\"\n",
    "    Process Taylor Swift data file with complete error handling.\n",
    "    Demonstrates try/except/else/finally pattern.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n🎵 Processing: {filename}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    file_handle = None\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Attempt to open and read file\n",
    "        print(f\"📁 Opening file: {filename}\")\n",
    "        file_handle = open(filename, 'r')\n",
    "        \n",
    "        print(f\"📖 Reading JSON data...\")\n",
    "        data = json.load(file_handle)\n",
    "        \n",
    "        print(f\"✅ File opened and parsed successfully\")\n",
    "        \n",
    "        # Validate data structure\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(f\"Expected dictionary, got {type(data)}\")\n",
    "        \n",
    "        if \"artist\" not in data:\n",
    "            raise KeyError(\"Missing 'artist' field\")\n",
    "        \n",
    "        if data[\"artist\"] != \"Taylor Swift\":\n",
    "            raise ValueError(f\"Expected Taylor Swift data, got {data['artist']}\")\n",
    "        \n",
    "        print(f\"✅ Data validation passed\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File not found: {filename}\")\n",
    "        return {\"status\": \"file_not_found\", \"filename\": filename}\n",
    "    \n",
    "    except PermissionError:\n",
    "        print(f\"❌ Permission denied: {filename}\")\n",
    "        return {\"status\": \"permission_denied\", \"filename\": filename}\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ Invalid JSON: {e}\")\n",
    "        return {\"status\": \"invalid_json\", \"filename\": filename, \"error\": str(e)}\n",
    "    \n",
    "    except (KeyError, ValueError) as e:\n",
    "        print(f\"❌ Data validation error: {e}\")\n",
    "        return {\"status\": \"validation_error\", \"filename\": filename, \"error\": str(e)}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        return {\"status\": \"unexpected_error\", \"filename\": filename, \"error\": str(e)}\n",
    "    \n",
    "    else:\n",
    "        # This runs only if no exceptions occurred\n",
    "        print(f\"🎉 Success! Processing data for {data['artist']}\")\n",
    "        \n",
    "        # Process the data\n",
    "        albums = data.get(\"albums\", [])\n",
    "        total_albums = len(albums)\n",
    "        \n",
    "        songs = []\n",
    "        for album in albums:\n",
    "            if isinstance(album, dict) and \"tracks\" in album:\n",
    "                songs.extend(album[\"tracks\"])\n",
    "        \n",
    "        result = {\n",
    "            \"status\": \"success\",\n",
    "            \"filename\": filename,\n",
    "            \"artist\": data[\"artist\"],\n",
    "            \"total_albums\": total_albums,\n",
    "            \"total_songs\": len(songs),\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        print(f\"📊 Found {total_albums} albums with {len(songs)} total songs\")\n",
    "        return result\n",
    "    \n",
    "    finally:\n",
    "        # This always runs, whether exception occurred or not\n",
    "        end_time = datetime.now()\n",
    "        processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"⏱️ Processing time: {processing_time:.3f} seconds\")\n",
    "        \n",
    "        # Clean up resources\n",
    "        if file_handle:\n",
    "            file_handle.close()\n",
    "            print(f\"🔒 File closed: {filename}\")\n",
    "        \n",
    "        print(f\"🧹 Cleanup completed\")\n",
    "\n",
    "# Create test files\n",
    "print(\"=== Creating Test Files ===\")\n",
    "\n",
    "# Valid Taylor Swift data\n",
    "valid_data = {\n",
    "    \"artist\": \"Taylor Swift\",\n",
    "    \"albums\": [\n",
    "        {\n",
    "            \"title\": \"folklore\",\n",
    "            \"year\": 2020,\n",
    "            \"tracks\": [\"the 1\", \"cardigan\", \"august\"]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Midnights\",\n",
    "            \"year\": 2022,\n",
    "            \"tracks\": [\"Lavender Haze\", \"Anti-Hero\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"valid_taylor_data.json\", \"w\") as f:\n",
    "    json.dump(valid_data, f, indent=2)\n",
    "print(\"✓ Created valid_taylor_data.json\")\n",
    "\n",
    "# Invalid JSON file\n",
    "with open(\"invalid_json.json\", \"w\") as f:\n",
    "    f.write('{\"artist\": \"Taylor Swift\", \"invalid\": json}')\n",
    "print(\"✓ Created invalid_json.json\")\n",
    "\n",
    "# Wrong artist data\n",
    "wrong_artist_data = {\"artist\": \"Not Taylor Swift\", \"albums\": []}\n",
    "with open(\"wrong_artist.json\", \"w\") as f:\n",
    "    json.dump(wrong_artist_data, f)\n",
    "print(\"✓ Created wrong_artist.json\")\n",
    "\n",
    "# Test all scenarios\n",
    "test_files = [\n",
    "    \"valid_taylor_data.json\",\n",
    "    \"invalid_json.json\", \n",
    "    \"wrong_artist.json\",\n",
    "    \"nonexistent_file.json\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FILE PROCESSING TESTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "for filename in test_files:\n",
    "    result = process_taylor_data_file(filename)\n",
    "    results.append(result)\n",
    "\n",
    "# Summary\n",
    "successful = [r for r in results if r[\"status\"] == \"success\"]\n",
    "failed = [r for r in results if r[\"status\"] != \"success\"]\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 40)\n",
    "print(f\"PROCESSING SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"✅ Successful: {len(successful)} files\")\n",
    "print(f\"❌ Failed: {len(failed)} files\")\n",
    "\n",
    "if failed:\n",
    "    print(\"\\nFailure reasons:\")\n",
    "    failure_counts = {}\n",
    "    for result in failed:\n",
    "        status = result[\"status\"]\n",
    "        failure_counts[status] = failure_counts.get(status, 0) + 1\n",
    "    \n",
    "    for reason, count in failure_counts.items():\n",
    "        print(f\"  • {reason.replace('_', ' ').title()}: {count}\")\n",
    "\n",
    "print(f\"\\n🎯 Key lesson: try/except/else/finally provides complete error handling!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raising Custom Exceptions\n",
    "\n",
    "Create and raise your own exceptions for specific Taylor Swift data scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Custom exceptions for Taylor Swift data processing\n",
    "\n",
    "class TaylorSwiftDataError(Exception):\n",
    "    \"\"\"Base exception for Taylor Swift data processing errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class InvalidAlbumError(TaylorSwiftDataError):\n",
    "    \"\"\"Raised when album data is invalid.\"\"\"\n",
    "    def __init__(self, album_name, reason):\n",
    "        self.album_name = album_name\n",
    "        self.reason = reason\n",
    "        super().__init__(f\"Invalid album '{album_name}': {reason}\")\n",
    "\n",
    "class InvalidSongError(TaylorSwiftDataError):\n",
    "    \"\"\"Raised when song data is invalid.\"\"\"\n",
    "    def __init__(self, song_title, album, reason):\n",
    "        self.song_title = song_title\n",
    "        self.album = album\n",
    "        self.reason = reason\n",
    "        super().__init__(f\"Invalid song '{song_title}' from '{album}': {reason}\")\n",
    "\n",
    "class EraClassificationError(TaylorSwiftDataError):\n",
    "    \"\"\"Raised when album era cannot be determined.\"\"\"\n",
    "    def __init__(self, year):\n",
    "        self.year = year\n",
    "        super().__init__(f\"Cannot classify era for year {year}\")\n",
    "\n",
    "class StreamingDataError(TaylorSwiftDataError):\n",
    "    \"\"\"Raised when streaming data is unrealistic.\"\"\"\n",
    "    def __init__(self, song, streams, reason):\n",
    "        self.song = song\n",
    "        self.streams = streams\n",
    "        self.reason = reason\n",
    "        super().__init__(f\"Unrealistic streaming data for '{song}': {streams:,} streams ({reason})\")\n",
    "\n",
    "class TaylorSwiftValidator:\n",
    "    \"\"\"Validator for Taylor Swift data with custom exceptions.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_album(album_data):\n",
    "        \"\"\"Validate album data structure and content.\"\"\"\n",
    "        \n",
    "        # Check required fields\n",
    "        if not isinstance(album_data, dict):\n",
    "            raise InvalidAlbumError(\"Unknown\", \"Must be a dictionary\")\n",
    "        \n",
    "        required_fields = [\"title\", \"year\", \"genre\"]\n",
    "        for field in required_fields:\n",
    "            if field not in album_data:\n",
    "                album_name = album_data.get(\"title\", \"Unknown\")\n",
    "                raise InvalidAlbumError(album_name, f\"Missing required field: {field}\")\n",
    "        \n",
    "        album_name = album_data[\"title\"]\n",
    "        year = album_data[\"year\"]\n",
    "        genre = album_data[\"genre\"]\n",
    "        \n",
    "        # Validate year\n",
    "        if not isinstance(year, int):\n",
    "            raise InvalidAlbumError(album_name, f\"Year must be integer, got {type(year)}\")\n",
    "        \n",
    "        if year < 2006:\n",
    "            raise InvalidAlbumError(album_name, f\"Year {year} is before Taylor's debut (2006)\")\n",
    "        \n",
    "        if year > 2030:\n",
    "            raise InvalidAlbumError(album_name, f\"Year {year} is unrealistically far in the future\")\n",
    "        \n",
    "        # Validate genre\n",
    "        valid_genres = [\"Country\", \"Pop\", \"Alternative\", \"Folk\", \"Rock\", \"Country-Pop\"]\n",
    "        if genre not in valid_genres:\n",
    "            raise InvalidAlbumError(album_name, f\"Invalid genre '{genre}'. Valid: {valid_genres}\")\n",
    "        \n",
    "        # Validate tracks if present\n",
    "        if \"tracks\" in album_data:\n",
    "            tracks = album_data[\"tracks\"]\n",
    "            if not isinstance(tracks, list):\n",
    "                raise InvalidAlbumError(album_name, \"Tracks must be a list\")\n",
    "            \n",
    "            if len(tracks) == 0:\n",
    "                raise InvalidAlbumError(album_name, \"Album must have at least one track\")\n",
    "            \n",
    "            if len(tracks) > 50:\n",
    "                raise InvalidAlbumError(album_name, f\"Too many tracks: {len(tracks)} (max 50)\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_song(song_data, album_name=\"Unknown\"):\n",
    "        \"\"\"Validate individual song data.\"\"\"\n",
    "        \n",
    "        if not isinstance(song_data, dict):\n",
    "            raise InvalidSongError(\"Unknown\", album_name, \"Must be a dictionary\")\n",
    "        \n",
    "        if \"title\" not in song_data:\n",
    "            raise InvalidSongError(\"Unknown\", album_name, \"Missing song title\")\n",
    "        \n",
    "        song_title = song_data[\"title\"]\n",
    "        \n",
    "        # Validate title\n",
    "        if not isinstance(song_title, str) or len(song_title.strip()) == 0:\n",
    "            raise InvalidSongError(song_title, album_name, \"Title must be non-empty string\")\n",
    "        \n",
    "        # Validate duration if present\n",
    "        if \"duration\" in song_data:\n",
    "            duration = song_data[\"duration\"]\n",
    "            if isinstance(duration, str):\n",
    "                # Parse MM:SS format\n",
    "                if \":\" not in duration:\n",
    "                    raise InvalidSongError(song_title, album_name, f\"Invalid duration format: '{duration}'\")\n",
    "                \n",
    "                parts = duration.split(\":\")\n",
    "                if len(parts) != 2:\n",
    "                    raise InvalidSongError(song_title, album_name, f\"Invalid duration format: '{duration}'\")\n",
    "                \n",
    "                try:\n",
    "                    minutes = int(parts[0])\n",
    "                    seconds = int(parts[1])\n",
    "                    total_seconds = minutes * 60 + seconds\n",
    "                except ValueError:\n",
    "                    raise InvalidSongError(song_title, album_name, f\"Non-numeric duration: '{duration}'\")\n",
    "                \n",
    "                if total_seconds < 30:\n",
    "                    raise InvalidSongError(song_title, album_name, f\"Duration too short: {duration}\")\n",
    "                \n",
    "                if total_seconds > 900:  # 15 minutes\n",
    "                    raise InvalidSongError(song_title, album_name, f\"Duration too long: {duration}\")\n",
    "        \n",
    "        # Validate streams if present\n",
    "        if \"streams\" in song_data:\n",
    "            streams = song_data[\"streams\"]\n",
    "            if not isinstance(streams, int) or streams < 0:\n",
    "                raise StreamingDataError(song_title, streams, \"Streams must be non-negative integer\")\n",
    "            \n",
    "            if streams > 5_000_000_000:  # 5 billion seems like a reasonable upper limit\n",
    "                raise StreamingDataError(song_title, streams, \"Unrealistically high stream count\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def classify_era(year):\n",
    "        \"\"\"Classify album era based on year.\"\"\"\n",
    "        \n",
    "        if year < 2006:\n",
    "            raise EraClassificationError(year)\n",
    "        elif year <= 2012:\n",
    "            return \"Country Era\"\n",
    "        elif year <= 2017:\n",
    "            return \"Pop Era\"\n",
    "        elif year <= 2019:\n",
    "            return \"Reputation/Lover Era\"\n",
    "        elif year <= 2021:\n",
    "            return \"Folklore/Evermore Era\"\n",
    "        elif year <= 2025:\n",
    "            return \"Midnights+ Era\"\n",
    "        else:\n",
    "            raise EraClassificationError(year)\n",
    "\n",
    "# Test custom exceptions\n",
    "print(\"=== Testing Custom Exceptions ===\")\n",
    "\n",
    "test_albums = [\n",
    "    # Valid album\n",
    "    {\"title\": \"folklore\", \"year\": 2020, \"genre\": \"Alternative\", \"tracks\": [\n",
    "        {\"title\": \"cardigan\", \"duration\": \"3:59\", \"streams\": 800000000}\n",
    "    ]},\n",
    "    \n",
    "    # Invalid year\n",
    "    {\"title\": \"Future Album\", \"year\": 2040, \"genre\": \"Pop\"},\n",
    "    \n",
    "    # Invalid genre\n",
    "    {\"title\": \"Heavy Metal Album\", \"year\": 2023, \"genre\": \"Death Metal\"},\n",
    "    \n",
    "    # Missing fields\n",
    "    {\"title\": \"Incomplete Album\", \"year\": 2020},\n",
    "    \n",
    "    # Invalid track data\n",
    "    {\"title\": \"Bad Tracks Album\", \"year\": 2021, \"genre\": \"Pop\", \"tracks\": [\n",
    "        {\"title\": \"Good Song\", \"duration\": \"3:20\"},\n",
    "        {\"title\": \"Bad Duration Song\", \"duration\": \"0:10\"},  # Too short\n",
    "        {\"title\": \"Crazy Streams Song\", \"streams\": 10_000_000_000}  # Too many streams\n",
    "    ]}\n",
    "]\n",
    "\n",
    "validator = TaylorSwiftValidator()\n",
    "\n",
    "for i, album in enumerate(test_albums, 1):\n",
    "    print(f\"\\nTesting Album {i}: {album.get('title', 'Unknown')}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Validate album\n",
    "        validator.validate_album(album)\n",
    "        print(f\"✅ Album validation passed\")\n",
    "        \n",
    "        # Classify era\n",
    "        era = validator.classify_era(album[\"year\"])\n",
    "        print(f\"🎭 Era: {era}\")\n",
    "        \n",
    "        # Validate individual tracks\n",
    "        if \"tracks\" in album:\n",
    "            for track in album[\"tracks\"]:\n",
    "                try:\n",
    "                    validator.validate_song(track, album[\"title\"])\n",
    "                    print(f\"  ✅ Track '{track['title']}' is valid\")\n",
    "                except (InvalidSongError, StreamingDataError) as e:\n",
    "                    print(f\"  ❌ Track error: {e}\")\n",
    "    \n",
    "    except InvalidAlbumError as e:\n",
    "        print(f\"❌ Album Error: {e}\")\n",
    "        print(f\"   Album: {e.album_name}\")\n",
    "        print(f\"   Reason: {e.reason}\")\n",
    "    \n",
    "    except EraClassificationError as e:\n",
    "        print(f\"❌ Era Error: {e}\")\n",
    "        print(f\"   Year: {e.year}\")\n",
    "    \n",
    "    except TaylorSwiftDataError as e:\n",
    "        print(f\"❌ Taylor Swift Data Error: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected Error: {e}\")\n",
    "\n",
    "print(f\"\\n🎯 Custom exceptions provide specific, actionable error messages!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Techniques\n",
    "\n",
    "Learn to debug Taylor Swift data processing issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import traceback\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging for debugging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),  # Console output\n",
    "        logging.FileHandler('taylor_debug.log')  # File output\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def debug_song_analysis(songs_data):\n",
    "    \"\"\"\n",
    "    Analyze songs with extensive debugging information.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f\"Starting song analysis with {len(songs_data)} songs\")\n",
    "    \n",
    "    results = {\n",
    "        \"processed\": 0,\n",
    "        \"errors\": 0,\n",
    "        \"total_duration\": 0,\n",
    "        \"error_details\": []\n",
    "    }\n",
    "    \n",
    "    for i, song in enumerate(songs_data):\n",
    "        logger.debug(f\"Processing song {i+1}/{len(songs_data)}: {song}\")\n",
    "        \n",
    "        try:\n",
    "            # Extract song data\n",
    "            title = song[\"title\"]\n",
    "            logger.debug(f\"  Title: {title}\")\n",
    "            \n",
    "            # Parse duration\n",
    "            duration_str = song[\"duration\"]\n",
    "            logger.debug(f\"  Duration string: {duration_str}\")\n",
    "            \n",
    "            # Add debugging breakpoint\n",
    "            if title == \"Debug Song\":\n",
    "                logger.warning(f\"Debugging breakpoint reached for: {title}\")\n",
    "                # In real debugging, you might use: import pdb; pdb.set_trace()\n",
    "            \n",
    "            parts = duration_str.split(\":\")\n",
    "            logger.debug(f\"  Duration parts: {parts}\")\n",
    "            \n",
    "            if len(parts) != 2:\n",
    "                raise ValueError(f\"Expected 2 parts (MM:SS), got {len(parts)}\")\n",
    "            \n",
    "            minutes = int(parts[0])\n",
    "            seconds = int(parts[1])\n",
    "            total_seconds = minutes * 60 + seconds\n",
    "            \n",
    "            logger.debug(f\"  Parsed duration: {minutes}m {seconds}s = {total_seconds}s\")\n",
    "            \n",
    "            # Validate duration\n",
    "            if total_seconds <= 0:\n",
    "                raise ValueError(f\"Invalid duration: {total_seconds} seconds\")\n",
    "            \n",
    "            if total_seconds > 600:  # 10 minutes\n",
    "                logger.warning(f\"Unusually long song: {title} ({total_seconds}s)\")\n",
    "            \n",
    "            # Success\n",
    "            results[\"processed\"] += 1\n",
    "            results[\"total_duration\"] += total_seconds\n",
    "            \n",
    "            logger.info(f\"  ✅ Successfully processed: {title} ({duration_str})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Detailed error logging\n",
    "            results[\"errors\"] += 1\n",
    "            \n",
    "            error_info = {\n",
    "                \"song_index\": i,\n",
    "                \"song_data\": song,\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error_message\": str(e),\n",
    "                \"traceback\": traceback.format_exc()\n",
    "            }\n",
    "            \n",
    "            results[\"error_details\"].append(error_info)\n",
    "            \n",
    "            logger.error(f\"  ❌ Error processing song {i+1}: {e}\")\n",
    "            logger.debug(f\"  Song data: {song}\")\n",
    "            logger.debug(f\"  Full traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    logger.info(f\"Analysis complete: {results['processed']} processed, {results['errors']} errors\")\n",
    "    return results\n",
    "\n",
    "def advanced_error_analysis(error_results):\n",
    "    \"\"\"\n",
    "    Analyze error patterns for debugging insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not error_results[\"error_details\"]:\n",
    "        print(\"✅ No errors to analyze!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n🔍 ERROR ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Group errors by type\n",
    "    error_types = {}\n",
    "    for error in error_results[\"error_details\"]:\n",
    "        error_type = error[\"error_type\"]\n",
    "        if error_type not in error_types:\n",
    "            error_types[error_type] = []\n",
    "        error_types[error_type].append(error)\n",
    "    \n",
    "    print(f\"Error types found: {len(error_types)}\")\n",
    "    for error_type, errors in error_types.items():\n",
    "        print(f\"  • {error_type}: {len(errors)} occurrences\")\n",
    "    \n",
    "    # Show detailed analysis for each error type\n",
    "    for error_type, errors in error_types.items():\n",
    "        print(f\"\\n--- {error_type} Analysis ---\")\n",
    "        \n",
    "        for i, error in enumerate(errors, 1):\n",
    "            print(f\"\\nError {i}:\")\n",
    "            print(f\"  Song: {error['song_data'].get('title', 'Unknown')}\")\n",
    "            print(f\"  Message: {error['error_message']}\")\n",
    "            print(f\"  Data: {error['song_data']}\")\n",
    "            \n",
    "            # Show stack trace for debugging\n",
    "            if i <= 2:  # Only show first 2 to avoid clutter\n",
    "                print(f\"  Stack trace:\")\n",
    "                trace_lines = error['traceback'].strip().split('\\n')\n",
    "                for line in trace_lines[-3:]:  # Show last 3 lines\n",
    "                    print(f\"    {line}\")\n",
    "    \n",
    "    # Suggest fixes\n",
    "    print(f\"\\n💡 DEBUGGING SUGGESTIONS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if \"ValueError\" in error_types:\n",
    "        print(\"• ValueError: Check data format and validation logic\")\n",
    "        print(\"  - Verify duration format (MM:SS)\")\n",
    "        print(\"  - Check for negative or zero values\")\n",
    "    \n",
    "    if \"KeyError\" in error_types:\n",
    "        print(\"• KeyError: Missing required fields in data\")\n",
    "        print(\"  - Add validation for required fields\")\n",
    "        print(\"  - Use .get() method with defaults\")\n",
    "    \n",
    "    if \"TypeError\" in error_types:\n",
    "        print(\"• TypeError: Unexpected data types\")\n",
    "        print(\"  - Add type checking before operations\")\n",
    "        print(\"  - Convert types explicitly when needed\")\n",
    "\n",
    "# Test data with various error conditions for debugging\n",
    "debug_songs = [\n",
    "    {\"title\": \"Love Story\", \"duration\": \"3:55\"},  # Valid\n",
    "    {\"title\": \"Bad Duration 1\", \"duration\": \"invalid\"},  # Invalid format\n",
    "    {\"title\": \"Bad Duration 2\", \"duration\": \"3:75\"},  # Invalid seconds\n",
    "    {\"title\": \"Missing Duration\"},  # Missing field\n",
    "    {\"title\": \"Zero Duration\", \"duration\": \"0:00\"},  # Zero duration\n",
    "    {\"title\": \"Negative Duration\", \"duration\": \"-1:30\"},  # Negative\n",
    "    {\"title\": \"Long Song\", \"duration\": \"12:00\"},  # Very long\n",
    "    {\"title\": \"Debug Song\", \"duration\": \"4:20\"},  # Debugging breakpoint\n",
    "    {\"title\": \"Good Song\", \"duration\": \"3:30\"},  # Valid\n",
    "]\n",
    "\n",
    "print(\"=== DEBUGGING DEMONSTRATION ===\")\n",
    "print(f\"Processing {len(debug_songs)} test songs with intentional errors...\")\n",
    "\n",
    "# Run analysis with debugging\n",
    "results = debug_song_analysis(debug_songs)\n",
    "\n",
    "# Show summary\n",
    "print(f\"\\n📊 PROCESSING SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"✅ Successful: {results['processed']}\")\n",
    "print(f\"❌ Errors: {results['errors']}\")\n",
    "print(f\"⏱️ Total duration: {results['total_duration']} seconds\")\n",
    "\n",
    "if results[\"processed\"] > 0:\n",
    "    avg_duration = results[\"total_duration\"] / results[\"processed\"]\n",
    "    print(f\"📈 Average duration: {avg_duration:.1f} seconds\")\n",
    "\n",
    "# Detailed error analysis\n",
    "if results[\"errors\"] > 0:\n",
    "    advanced_error_analysis(results)\n",
    "\n",
    "# Show log file info\n",
    "print(f\"\\n📝 Debug log saved to: taylor_debug.log\")\n",
    "print(f\"💡 Use logging.DEBUG level for detailed debugging information\")\n",
    "print(f\"🐛 In production, use logging.INFO or logging.WARNING\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Time! 🎵\n",
    "\n",
    "Let's practice error handling techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Practice Exercise 1:\n",
    "# Create a function that safely calculates Taylor Swift streaming statistics\n",
    "# Handle various error conditions: missing data, invalid types, zero values\n",
    "\n",
    "def safe_streaming_stats(songs_list):\n",
    "    \"\"\"\n",
    "    Calculate streaming statistics with comprehensive error handling.\n",
    "    \n",
    "    Args:\n",
    "        songs_list: List of song dictionaries with 'title' and 'streams'\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with statistics or error information\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    # Handle: empty list, missing fields, invalid stream counts, type errors\n",
    "    # Return: total streams, average, min, max, or error details\n",
    "    pass\n",
    "\n",
    "# Test data\n",
    "test_streaming_data = [\n",
    "    {\"title\": \"Love Story\", \"streams\": 500000000},\n",
    "    {\"title\": \"Bad Data 1\", \"streams\": \"not_a_number\"},\n",
    "    {\"title\": \"Bad Data 2\"},  # Missing streams\n",
    "    {\"title\": \"Shake It Off\", \"streams\": 800000000},\n",
    "    {\"title\": \"Bad Data 3\", \"streams\": -100},  # Negative streams\n",
    "]\n",
    "\n",
    "# Test your function\n",
    "# result = safe_streaming_stats(test_streaming_data)\n",
    "# print(f\"Result: {result}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Practice Exercise 2:\n",
    "# Create a custom exception hierarchy for a Taylor Swift playlist system\n",
    "# Include: PlaylistError (base), EmptyPlaylistError, DuplicateSongError, InvalidDurationError\n",
    "\n",
    "class PlaylistError(Exception):\n",
    "    \"\"\"Base exception for playlist errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Your custom exceptions here:\n",
    "\n",
    "class PlaylistManager:\n",
    "    def __init__(self):\n",
    "        self.songs = []\n",
    "    \n",
    "    def add_song(self, title, duration):\n",
    "        \"\"\"\n",
    "        Add song with validation.\n",
    "        Raise appropriate exceptions for various error conditions.\n",
    "        \"\"\"\n",
    "        # Your code here:\n",
    "        # Check for duplicates, validate duration format, etc.\n",
    "        pass\n",
    "    \n",
    "    def get_total_duration(self):\n",
    "        \"\"\"\n",
    "        Calculate total playlist duration.\n",
    "        Raise EmptyPlaylistError if no songs.\n",
    "        \"\"\"\n",
    "        # Your code here:\n",
    "        pass\n",
    "\n",
    "# Test your playlist manager\n",
    "# manager = PlaylistManager()\n",
    "# try:\n",
    "#     manager.add_song(\"Love Story\", \"3:55\")\n",
    "#     manager.add_song(\"Love Story\", \"3:55\")  # Should raise DuplicateSongError\n",
    "# except PlaylistError as e:\n",
    "#     print(f\"Playlist error: {e}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Practice Exercise 3:\n",
    "# Create a robust data loader that handles multiple file formats\n",
    "# Use try/except/else/finally pattern appropriately\n",
    "\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def robust_taylor_data_loader(file_path, expected_format=None):\n",
    "    \"\"\"\n",
    "    Load Taylor Swift data from various file formats with complete error handling.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to data file\n",
    "        expected_format: 'json', 'csv', or None (auto-detect)\n",
    "    \n",
    "    Returns:\n",
    "        Loaded data or None if error\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    # Use try/except/else/finally\n",
    "    # Handle: file not found, permission errors, format errors\n",
    "    # Auto-detect format from file extension if not specified\n",
    "    # Log processing time and cleanup resources\n",
    "    pass\n",
    "\n",
    "# Create test files and test your loader\n",
    "# test_files = [\"test.json\", \"test.csv\", \"nonexistent.txt\"]\n",
    "# for file_path in test_files:\n",
    "#     result = robust_taylor_data_loader(file_path)\n",
    "#     print(f\"{file_path}: {result is not None}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example: Production Error Handling\n",
    "\n",
    "Build a production-ready Taylor Swift data processing system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import logging\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "# Configure production logging\n",
    "def setup_production_logging():\n",
    "    \"\"\"Set up production-grade logging.\"\"\"\n",
    "    \n",
    "    # Create logs directory\n",
    "    log_dir = Path(\"logs\")\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Configure logging\n",
    "    logger = logging.getLogger(\"TaylorSwiftProcessor\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Clear existing handlers\n",
    "    logger.handlers.clear()\n",
    "    \n",
    "    # File handler for all logs\n",
    "    file_handler = logging.FileHandler(log_dir / \"taylor_processor.log\")\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    \n",
    "    # Error file handler\n",
    "    error_handler = logging.FileHandler(log_dir / \"taylor_errors.log\")\n",
    "    error_handler.setLevel(logging.ERROR)\n",
    "    \n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.WARNING)\n",
    "    \n",
    "    # Formatter\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    "    )\n",
    "    \n",
    "    for handler in [file_handler, error_handler, console_handler]:\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "class TaylorSwiftDataProcessorPro:\n",
    "    \"\"\"\n",
    "    Production-ready Taylor Swift data processor with comprehensive error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = setup_production_logging()\n",
    "        self.processed_count = 0\n",
    "        self.error_count = 0\n",
    "        self.start_time = None\n",
    "        self.error_summary = {}\n",
    "        \n",
    "        self.logger.info(\"TaylorSwiftDataProcessorPro initialized\")\n",
    "    \n",
    "    def process_batch(self, data_batch: List[Dict[str, Any]], batch_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a batch of Taylor Swift data with full error handling.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.start_time = datetime.now()\n",
    "        self.logger.info(f\"Starting batch {batch_id} with {len(data_batch)} items\")\n",
    "        \n",
    "        batch_results = {\n",
    "            'batch_id': batch_id,\n",
    "            'start_time': self.start_time.isoformat(),\n",
    "            'total_items': len(data_batch),\n",
    "            'processed_items': [],\n",
    "            'failed_items': [],\n",
    "            'processing_errors': [],\n",
    "            'status': 'running'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Process each item in the batch\n",
    "            for i, item in enumerate(data_batch):\n",
    "                item_id = f\"{batch_id}_item_{i+1}\"\n",
    "                \n",
    "                try:\n",
    "                    processed_item = self._process_single_item(item, item_id)\n",
    "                    batch_results['processed_items'].append(processed_item)\n",
    "                    self.processed_count += 1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    error_info = self._handle_item_error(e, item, item_id)\n",
    "                    batch_results['failed_items'].append(error_info)\n",
    "                    batch_results['processing_errors'].append(error_info)\n",
    "                    self.error_count += 1\n",
    "                    \n",
    "                    # Continue processing other items\n",
    "                    continue\n",
    "            \n",
    "            # Batch completed successfully\n",
    "            batch_results['status'] = 'completed'\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Critical batch-level error\n",
    "            self.logger.critical(f\"Critical error in batch {batch_id}: {e}\")\n",
    "            self.logger.critical(f\"Traceback: {traceback.format_exc()}\")\n",
    "            \n",
    "            batch_results['status'] = 'failed'\n",
    "            batch_results['critical_error'] = {\n",
    "                'error_type': type(e).__name__,\n",
    "                'error_message': str(e),\n",
    "                'traceback': traceback.format_exc()\n",
    "            }\n",
    "        \n",
    "        finally:\n",
    "            # Always complete batch metadata\n",
    "            end_time = datetime.now()\n",
    "            processing_time = (end_time - self.start_time).total_seconds()\n",
    "            \n",
    "            batch_results.update({\n",
    "                'end_time': end_time.isoformat(),\n",
    "                'processing_time_seconds': processing_time,\n",
    "                'success_rate': len(batch_results['processed_items']) / len(data_batch) if data_batch else 0,\n",
    "                'items_per_second': len(batch_results['processed_items']) / processing_time if processing_time > 0 else 0\n",
    "            })\n",
    "            \n",
    "            self.logger.info(\n",
    "                f\"Batch {batch_id} completed: {len(batch_results['processed_items'])} processed, \"\n",
    "                f\"{len(batch_results['failed_items'])} failed, {processing_time:.2f}s\"\n",
    "            )\n",
    "            \n",
    "            # Save batch results\n",
    "            self._save_batch_results(batch_results)\n",
    "        \n",
    "        return batch_results\n",
    "    \n",
    "    def _process_single_item(self, item: Dict[str, Any], item_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a single data item with validation.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.debug(f\"Processing item {item_id}: {item}\")\n",
    "        \n",
    "        # Validate required fields\n",
    "        required_fields = ['title', 'album', 'year']\n",
    "        for field in required_fields:\n",
    "            if field not in item:\n",
    "                raise ValueError(f\"Missing required field: {field}\")\n",
    "        \n",
    "        # Validate data types\n",
    "        if not isinstance(item['year'], int):\n",
    "            raise TypeError(f\"Year must be integer, got {type(item['year'])}\")\n",
    "        \n",
    "        if item['year'] < 2006 or item['year'] > 2030:\n",
    "            raise ValueError(f\"Invalid year: {item['year']}\")\n",
    "        \n",
    "        # Process optional fields\n",
    "        processed_item = {\n",
    "            'item_id': item_id,\n",
    "            'title': item['title'].strip(),\n",
    "            'album': item['album'].strip(),\n",
    "            'year': item['year'],\n",
    "            'processed_at': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Handle duration if present\n",
    "        if 'duration' in item:\n",
    "            try:\n",
    "                duration_seconds = self._parse_duration(item['duration'])\n",
    "                processed_item['duration_seconds'] = duration_seconds\n",
    "            except ValueError as e:\n",
    "                self.logger.warning(f\"Invalid duration in {item_id}: {e}\")\n",
    "                # Continue without duration rather than failing\n",
    "        \n",
    "        # Handle streams if present\n",
    "        if 'streams' in item:\n",
    "            try:\n",
    "                streams = int(item['streams'])\n",
    "                if streams < 0:\n",
    "                    raise ValueError(\"Streams cannot be negative\")\n",
    "                processed_item['streams'] = streams\n",
    "            except (ValueError, TypeError) as e:\n",
    "                self.logger.warning(f\"Invalid streams in {item_id}: {e}\")\n",
    "                # Continue without streams rather than failing\n",
    "        \n",
    "        self.logger.debug(f\"Successfully processed item {item_id}\")\n",
    "        return processed_item\n",
    "    \n",
    "    def _parse_duration(self, duration_str: str) -> int:\n",
    "        \"\"\"Parse duration string to seconds.\"\"\"\n",
    "        \n",
    "        if not isinstance(duration_str, str):\n",
    "            raise ValueError(f\"Duration must be string, got {type(duration_str)}\")\n",
    "        \n",
    "        if ':' not in duration_str:\n",
    "            raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
    "        \n",
    "        parts = duration_str.split(':')\n",
    "        if len(parts) != 2:\n",
    "            raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
    "        \n",
    "        try:\n",
    "            minutes = int(parts[0])\n",
    "            seconds = int(parts[1])\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Non-numeric duration: {duration_str}\")\n",
    "        \n",
    "        if minutes < 0 or seconds < 0 or seconds >= 60:\n",
    "            raise ValueError(f\"Invalid time values: {minutes}:{seconds}\")\n",
    "        \n",
    "        return minutes * 60 + seconds\n",
    "    \n",
    "    def _handle_item_error(self, error: Exception, item: Dict[str, Any], item_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle and log individual item errors.\n",
    "        \"\"\"\n",
    "        \n",
    "        error_type = type(error).__name__\n",
    "        error_message = str(error)\n",
    "        \n",
    "        # Track error frequency for reporting\n",
    "        if error_type not in self.error_summary:\n",
    "            self.error_summary[error_type] = 0\n",
    "        self.error_summary[error_type] += 1\n",
    "        \n",
    "        error_info = {\n",
    "            'item_id': item_id,\n",
    "            'item_data': item,\n",
    "            'error_type': error_type,\n",
    "            'error_message': error_message,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Log appropriate level based on error type\n",
    "        if error_type in ['ValueError', 'TypeError']:\n",
    "            self.logger.warning(f\"Data error in {item_id}: {error_message}\")\n",
    "        else:\n",
    "            self.logger.error(f\"Unexpected error in {item_id}: {error_message}\")\n",
    "            self.logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        \n",
    "        return error_info\n",
    "    \n",
    "    def _save_batch_results(self, batch_results: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Save batch results to file.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            results_dir = Path(\"batch_results\")\n",
    "            results_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            batch_id = batch_results['batch_id']\n",
    "            filename = f\"{batch_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            filepath = results_dir / filename\n",
    "            \n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(batch_results, f, indent=2)\n",
    "            \n",
    "            self.logger.info(f\"Batch results saved to {filepath}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to save batch results: {e}\")\n",
    "    \n",
    "    def get_processing_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get overall processing summary.\n",
    "        \"\"\"\n",
    "        \n",
    "        total_items = self.processed_count + self.error_count\n",
    "        success_rate = self.processed_count / total_items if total_items > 0 else 0\n",
    "        \n",
    "        summary = {\n",
    "            'total_processed': self.processed_count,\n",
    "            'total_errors': self.error_count,\n",
    "            'total_items': total_items,\n",
    "            'success_rate': success_rate,\n",
    "            'error_summary': self.error_summary.copy(),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Test the production system\n",
    "print(\"🏭 PRODUCTION ERROR HANDLING DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "processor = TaylorSwiftDataProcessorPro()\n",
    "\n",
    "# Test data with various error conditions\n",
    "test_batches = {\n",
    "    \"batch_001\": [\n",
    "        {\"title\": \"Love Story\", \"album\": \"Fearless\", \"year\": 2008, \"duration\": \"3:55\", \"streams\": 500000000},\n",
    "        {\"title\": \"Shake It Off\", \"album\": \"1989\", \"year\": 2014, \"duration\": \"3:39\", \"streams\": 800000000},\n",
    "        {\"title\": \"cardigan\", \"album\": \"folklore\", \"year\": 2020, \"duration\": \"3:59\", \"streams\": 650000000}\n",
    "    ],\n",
    "    \n",
    "    \"batch_002\": [\n",
    "        {\"title\": \"Good Song\", \"album\": \"Good Album\", \"year\": 2021},  # Valid minimal data\n",
    "        {\"title\": \"Bad Year Song\", \"album\": \"Album\", \"year\": 1990},  # Invalid year\n",
    "        {\"title\": \"Missing Album\", \"year\": 2020},  # Missing required field\n",
    "        {\"title\": \"Bad Duration\", \"album\": \"Album\", \"year\": 2022, \"duration\": \"invalid\"},  # Bad duration\n",
    "        {\"title\": \"Bad Streams\", \"album\": \"Album\", \"year\": 2023, \"streams\": \"not_a_number\"}  # Bad streams\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Process all batches\n",
    "all_results = []\n",
    "for batch_id, batch_data in test_batches.items():\n",
    "    print(f\"\\nProcessing {batch_id}...\")\n",
    "    result = processor.process_batch(batch_data, batch_id)\n",
    "    all_results.append(result)\n",
    "    \n",
    "    # Show batch summary\n",
    "    print(f\"  Status: {result['status']}\")\n",
    "    print(f\"  Success rate: {result['success_rate']:.1%}\")\n",
    "    print(f\"  Processing time: {result['processing_time_seconds']:.2f}s\")\n",
    "\n",
    "# Overall summary\n",
    "summary = processor.get_processing_summary()\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 40)\n",
    "print(f\"FINAL PROCESSING SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"✅ Total processed: {summary['total_processed']}\")\n",
    "print(f\"❌ Total errors: {summary['total_errors']}\")\n",
    "print(f\"📊 Success rate: {summary['success_rate']:.1%}\")\n",
    "\n",
    "if summary['error_summary']:\n",
    "    print(f\"\\nError breakdown:\")\n",
    "    for error_type, count in summary['error_summary'].items():\n",
    "        print(f\"  • {error_type}: {count}\")\n",
    "\n",
    "print(f\"\\n📁 Check logs/ and batch_results/ directories for detailed output\")\n",
    "print(f\"🔧 Production system handles errors gracefully and continues processing!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Exception Types\n",
    "- **ValueError**: Invalid value for operation (wrong format, out of range)\n",
    "- **TypeError**: Wrong data type for operation\n",
    "- **KeyError**: Missing dictionary key\n",
    "- **IndexError**: Invalid list/string index\n",
    "- **AttributeError**: Non-existent attribute/method\n",
    "- **FileNotFoundError**: File doesn't exist\n",
    "- **PermissionError**: Insufficient file permissions\n",
    "- **ZeroDivisionError**: Division by zero\n",
    "\n",
    "### Try/Except Patterns\n",
    "- **Basic**: `try: ... except Exception: ...`\n",
    "- **Specific**: `except ValueError as e:` for targeted handling\n",
    "- **Multiple**: `except (ValueError, TypeError) as e:` for similar handling\n",
    "- **Catch-all**: `except Exception as e:` for unexpected errors\n",
    "- **Re-raising**: `raise` to let errors bubble up\n",
    "\n",
    "### Complete Error Handling\n",
    "- **try**: Code that might raise exceptions\n",
    "- **except**: Handle specific exception types\n",
    "- **else**: Runs only if no exceptions occurred\n",
    "- **finally**: Always runs (cleanup, logging, resource management)\n",
    "\n",
    "### Custom Exceptions\n",
    "- **Inherit from Exception**: Create domain-specific errors\n",
    "- **Add context**: Include relevant data in exception objects\n",
    "- **Clear messages**: Provide actionable error descriptions\n",
    "- **Exception hierarchy**: Group related exceptions under base classes\n",
    "\n",
    "### Error Handling Best Practices\n",
    "- **Be specific**: Catch specific exceptions rather than generic Exception\n",
    "- **Log errors**: Use logging module for production error tracking\n",
    "- **Fail gracefully**: Continue processing when possible\n",
    "- **Provide context**: Include relevant data in error messages\n",
    "- **Document exceptions**: List possible exceptions in docstrings\n",
    "\n",
    "### Debugging Techniques\n",
    "- **Logging levels**: DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "- **Stack traces**: `traceback.format_exc()` for detailed error info\n",
    "- **Error analysis**: Group and analyze error patterns\n",
    "- **Breakpoints**: Use debugger or logging for investigation\n",
    "- **Error metrics**: Track error rates and types for monitoring\n",
    "\n",
    "### Production Considerations\n",
    "- **Comprehensive logging**: Log to files with rotation\n",
    "- **Error recovery**: Continue processing after non-critical errors\n",
    "- **Resource cleanup**: Always close files, connections in finally blocks\n",
    "- **Error reporting**: Save error details for analysis\n",
    "- **Monitoring**: Track error rates and success metrics\n",
    "\n",
    "### When to Use Each Pattern\n",
    "- **try/except**: When you expect specific errors and can handle them\n",
    "- **try/except/else**: When success case has additional processing\n",
    "- **try/finally**: When you need cleanup regardless of success/failure\n",
    "- **Custom exceptions**: When built-in exceptions don't provide enough context\n",
    "- **Logging**: Always in production systems for debugging and monitoring\n",
    "\n",
    "Congratulations! You've mastered error handling - a crucial skill for building robust applications. Next up: the capstone project where you'll apply everything you've learned! 🎤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}